{"speakers": [{"speaker": "SPEAKER_02", "timestamp": [0.0, 2.0], "text": " Sanjeev Rampal, C-NCF Ambassador, Cisco,"}, {"speaker": "SPEAKER_02", "timestamp": [2.0, 4.0], "text": " and C-NCF Ambassador,"}, {"speaker": "SPEAKER_02", "timestamp": [4.0, 6.0], "text": " are here to talk about storage for Kubernetes."}, {"speaker": "SPEAKER_02", "timestamp": [6.0, 8.0], "text": " Sanjeev Rampal, C-NCF Ambassador, Cisco,"}, {"speaker": "SPEAKER_02", "timestamp": [8.0, 10.0], "text": " and C-NCF Ambassador,"}, {"speaker": "SPEAKER_03", "timestamp": [10.0, 12.0], "text": " are here to talk about storage for Kubernetes."}, {"speaker": "SPEAKER_03", "timestamp": [12.0, 14.0], "text": " Sanjeev Rampal, C-NCF Ambassador,"}, {"speaker": "SPEAKER_03", "timestamp": [14.0, 16.0], "text": " and C-NCF Ambassador,"}, {"speaker": "SPEAKER_03", "timestamp": [16.0, 18.0], "text": " are here to talk about storage for Kubernetes."}, {"speaker": "SPEAKER_03", "timestamp": [18.0, 20.0], "text": " Welcome to today's C-NCF webinar."}, {"speaker": "SPEAKER_03", "timestamp": [20.0, 22.0], "text": " Everything you need to know about storage for Kubernetes."}, {"speaker": "SPEAKER_03", "timestamp": [22.0, 24.0], "text": " Everything you need to know about storage for Kubernetes."}, {"speaker": "SPEAKER_03", "timestamp": [24.0, 25.68], "text": " My name is Sanjeev Rampal."}, {"speaker": "SPEAKER_03", "timestamp": [25.68, 29.82], "text": " I'm a principal engineer at Cisco and a CNCF ambassador."}, {"speaker": "SPEAKER_03", "timestamp": [29.82, 32.12], "text": " I'll be moderating today's webinar."}, {"speaker": "SPEAKER_03", "timestamp": [32.12, 36.0], "text": " We would like to welcome our presenter today, Alex Chirkop,"}, {"speaker": "SPEAKER_03", "timestamp": [36.0, 39.66], "text": " founder and CEO at StorageOS."}, {"speaker": "SPEAKER_03", "timestamp": [39.66, 43.0], "text": " Before we get started, a few housekeeping items."}, {"speaker": "SPEAKER_03", "timestamp": [43.0, 45.78], "text": " During the webinar, you will not be able to talk as an"}, {"speaker": "SPEAKER_03", "timestamp": [45.78, 52.0], "text": " attendee. There is a Q&A box at the bottom of your screen. Please feel free to drop your questions in"}, {"speaker": "SPEAKER_03", "timestamp": [52.0, 59.26], "text": " there. And we'll get to as many as we can through the call and at the end. Note the Q&A box is"}, {"speaker": "SPEAKER_03", "timestamp": [59.26, 67.84], "text": " different from the chat box. Please use the Q&A box. This is an official webinar of the CNCF and as such is"}, {"speaker": "SPEAKER_03", "timestamp": [67.84, 73.9], "text": " subject to the CNCF Code of Conduct. Please do not add anything to the chat or questions that"}, {"speaker": "SPEAKER_03", "timestamp": [73.9, 79.3], "text": " would be in violation of that Code of Conduct. Basically, please be respectful of your fellow"}, {"speaker": "SPEAKER_03", "timestamp": [79.3, 87.96], "text": " participants and presenters. With that, I'm going to hand it over to Alex to kick off today's presentation."}, {"speaker": "SPEAKER_03", "timestamp": [88.4, 89.16], "text": " Please go ahead, Alex."}, {"speaker": "SPEAKER_00", "timestamp": [90.68, 94.56], "text": " So good morning, good afternoon, or good evening, wherever you are."}, {"speaker": "SPEAKER_00", "timestamp": [95.42, 98.96], "text": " Hope you're all staying safe and are all well."}, {"speaker": "SPEAKER_00", "timestamp": [99.88, 103.88], "text": " So just a little bit of introduction about myself."}, {"speaker": "SPEAKER_00", "timestamp": [104.32, 113.68], "text": " I'm one of the founders and the CEO of StorageOS, where we've been focusing on building a software-defined"}, {"speaker": "SPEAKER_00", "timestamp": [113.68, 115.46], "text": " cloud-native storage platform."}, {"speaker": "SPEAKER_00", "timestamp": [115.74, 120.06], "text": " And we'll talk a little bit about what a cloud-native storage platform means."}, {"speaker": "SPEAKER_00", "timestamp": [144.86, 147.28], "text": " I'm also the co-chair of the CNCF storage SIG and in the storage SIG we've been working on providing facilities like educational content, like landscape documents, as well as working with the TOC on some of the items, on some of the project reviews for projects that are looking"}, {"speaker": "SPEAKER_00", "timestamp": [147.28, 151.48], "text": " to join the CNCF or to graduate through the CNCF process."}, {"speaker": "SPEAKER_00", "timestamp": [152.54, 159.42], "text": " Before embarking on this startup adventure, I've spent 25 years in infrastructure engineering,"}, {"speaker": "SPEAKER_00", "timestamp": [159.66, 164.86], "text": " you know, trying to build some of the larger infrastructure environments."}, {"speaker": "SPEAKER_00", "timestamp": [165.0, 166.74], "text": " to build some of the larger infrastructure environments."}, {"speaker": "SPEAKER_00", "timestamp": [171.6, 173.7], "text": " I'm gonna get a little plugin for the CNCF SIG storage."}, {"speaker": "SPEAKER_00", "timestamp": [178.7, 178.94], "text": " All the calls are fully open and we meet twice a month."}, {"speaker": "SPEAKER_00", "timestamp": [181.66, 183.5], "text": " Sometimes it's to cover project reviews and project presentations from the community"}, {"speaker": "SPEAKER_00", "timestamp": [183.5, 185.04], "text": " and sometimes it's to work"}, {"speaker": "SPEAKER_00", "timestamp": [185.04, 193.04], "text": " together on different contents that we share through the SIG repo. It would be really great"}, {"speaker": "SPEAKER_00", "timestamp": [193.04, 201.76], "text": " to see some more members attend so feel free to sign up and we'd love to talk to you about"}, {"speaker": "SPEAKER_00", "timestamp": [203.2, 205.76], "text": " the projects that we're working on in the CNCF."}, {"speaker": "SPEAKER_00", "timestamp": [208.42, 215.34], "text": " What I'm going to do in terms of agenda today is I'm going to talk a little bit about some of the"}, {"speaker": "SPEAKER_00", "timestamp": [215.34, 227.08], "text": " challenges of storage in cloud-native environments and discuss some of the principles of what to look for in cloud-native storage environments."}, {"speaker": "SPEAKER_00", "timestamp": [227.9, 234.1], "text": " I'm then going to cover some of the aspects of the storage landscape, which are covered"}, {"speaker": "SPEAKER_00", "timestamp": [234.1, 240.0], "text": " from the CNCF landscape white paper document that we've created."}, {"speaker": "SPEAKER_00", "timestamp": [240.82, 254.68], "text": " And I'm also going to talk about some of the internals of how Kubernetes uses APIs like CSI to work with different storage providers to manage storage within their environment."}, {"speaker": "SPEAKER_00", "timestamp": [269.28, 275.96], "text": " Godz was heard, we'll move ahead and have a little demo where I can show the use of some of the Kubernetes technologies like storage classes and PVCs and PVs to run a stateful"}, {"speaker": "SPEAKER_00", "timestamp": [275.96, 283.08], "text": " workload like a database in Kubernetes."}, {"speaker": "SPEAKER_00", "timestamp": [283.08, 287.3], "text": " So first off, we want to discuss why is storage important."}, {"speaker": "SPEAKER_00", "timestamp": [287.7, 290.2], "text": " So I'm going to say something fairly controversial here."}, {"speaker": "SPEAKER_00", "timestamp": [291.82, 294.98], "text": " Despite everything about containers being stateless,"}, {"speaker": "SPEAKER_00", "timestamp": [295.58, 298.34], "text": " there is no such thing as a stateless architecture, right?"}, {"speaker": "SPEAKER_00", "timestamp": [298.34, 302.06], "text": " All applications are looking to store state somewhere,"}, {"speaker": "SPEAKER_00", "timestamp": [302.78, 306.44], "text": " whether it is consuming, whether those applications are"}, {"speaker": "SPEAKER_00", "timestamp": [306.44, 312.0], "text": " consuming services that exist outside of the Kubernetes cluster, or whether they're using"}, {"speaker": "SPEAKER_00", "timestamp": [312.0, 318.62], "text": " services or storage functionality that lives within the Kubernetes cluster. Now,"}, {"speaker": "SPEAKER_00", "timestamp": [319.72, 328.44], "text": " cloud native storage is a very different beast. When we talk about Kubernetes, we're very familiar with"}, {"speaker": "SPEAKER_00", "timestamp": [328.44, 337.72], "text": " the concept of pets versus cattle, right? So the concept that nodes are specially curated and have"}, {"speaker": "SPEAKER_00", "timestamp": [337.72, 345.04], "text": " special resources or special services is a complete anti-pattern to the way Kubernetes clusters are deployed."}, {"speaker": "SPEAKER_00", "timestamp": [345.86, 349.36], "text": " What we really want is we want an environment"}, {"speaker": "SPEAKER_00", "timestamp": [349.36, 353.92], "text": " where your Kubernetes cluster is treated like cattle."}, {"speaker": "SPEAKER_00", "timestamp": [353.92, 362.54], "text": " So every node is homogeneous and can be used to deploy applications."}, {"speaker": "SPEAKER_00", "timestamp": [362.88, 363.9], "text": " and can be used to deploy applications."}, {"speaker": "SPEAKER_00", "timestamp": [367.94, 368.9], "text": " Now, in much the same way that today,"}, {"speaker": "SPEAKER_00", "timestamp": [371.82, 374.5], "text": " a developer can use a bit of YAML to specify, hey, this is my application, this is what it looks like,"}, {"speaker": "SPEAKER_00", "timestamp": [374.5, 377.22], "text": " it needs this amount of CPU, this amount of memory,"}, {"speaker": "SPEAKER_00", "timestamp": [378.42, 381.18], "text": " and maybe some network connectivity."}, {"speaker": "SPEAKER_00", "timestamp": [383.14, 389.74], "text": " Kubernetes then goes away and takes that declaration or that piece of YAML"}, {"speaker": "SPEAKER_00", "timestamp": [389.74, 395.34], "text": " and kind of does a really good job at playing Tetris with your infrastructure."}, {"speaker": "SPEAKER_00", "timestamp": [395.6, 400.48], "text": " So it abstracts away all of the services that are available in the infrastructure and does"}, {"speaker": "SPEAKER_00", "timestamp": [400.48, 406.64], "text": " the best to fit the applications in the most efficient way to that deployment"}, {"speaker": "SPEAKER_00", "timestamp": [407.92, 415.6], "text": " and makes sure that we maintain rules to maintain scalability or health."}, {"speaker": "SPEAKER_00", "timestamp": [416.16, 423.2], "text": " So based on the fact that applications within Kubernetes use this sort of functionality,"}, {"speaker": "SPEAKER_00", "timestamp": [427.54, 434.2], "text": " Kubernetes use this sort of functionality. You should also look for a cloud native storage solution where the solution is both declarative and composable, right? And in order to do this,"}, {"speaker": "SPEAKER_00", "timestamp": [434.64, 442.76], "text": " you're looking for a storage system that has a rich API-driven process that Kubernetes can"}, {"speaker": "SPEAKER_00", "timestamp": [442.76, 447.52], "text": " interact with. So in much the same way that you specify CPU, memory,"}, {"speaker": "SPEAKER_00", "timestamp": [447.52, 452.32], "text": " and network requirements, you should also be able to specify something like, you know, I need"}, {"speaker": "SPEAKER_00", "timestamp": [452.32, 457.92], "text": " 100 gigabytes and it needs to have these sorts of storage attributes like replication or encryption"}, {"speaker": "SPEAKER_00", "timestamp": [457.92, 470.44], "text": " applied. The second challenge we see with cloudative storage is that data needs to be able to follow applications, right?"}, {"speaker": "SPEAKER_00", "timestamp": [470.56, 484.86], "text": " So in a traditional storage architecture, you're very often presenting volumes or consuming storage on specific servers or nodes or VMs."}, {"speaker": "SPEAKER_00", "timestamp": [489.72, 494.96], "text": " storage on specific servers or nodes or VMs. And in cloud-native storage, we have a major difference here. The storage isn't being consumed by the node, but rather it's being consumed by"}, {"speaker": "SPEAKER_00", "timestamp": [494.96, 499.86], "text": " the application that's running on the node. And a lot of effort obviously has gone into"}, {"speaker": "SPEAKER_00", "timestamp": [499.86, 506.78], "text": " containerizing the application and making the application portable. So this application can now run on any nodes in the cluster."}, {"speaker": "SPEAKER_00", "timestamp": [507.68, 512.6], "text": " So you need to make sure that the storage subsystem can also apply the same"}, {"speaker": "SPEAKER_00", "timestamp": [512.6, 518.08], "text": " rules and effectively be able to follow the application wherever it moves"}, {"speaker": "SPEAKER_00", "timestamp": [518.08, 521.02], "text": " within the data center or within the cluster."}, {"speaker": "SPEAKER_00", "timestamp": [522.6, 524.2], "text": " The other thing is, obviously,"}, {"speaker": "SPEAKER_00", "timestamp": [524.74, 527.2], "text": " since Kubernetes does such a great job"}, {"speaker": "SPEAKER_00", "timestamp": [527.2, 529.48], "text": " at abstracting away the infrastructure,"}, {"speaker": "SPEAKER_00", "timestamp": [529.82, 534.26], "text": " allowing you to effectively deploy an application"}, {"speaker": "SPEAKER_00", "timestamp": [534.26, 535.28], "text": " in much the same way,"}, {"speaker": "SPEAKER_00", "timestamp": [535.36, 538.22], "text": " whether you're running bare metal on-prem"}, {"speaker": "SPEAKER_00", "timestamp": [538.22, 541.84], "text": " or in VMs or in cloud instances,"}, {"speaker": "SPEAKER_00", "timestamp": [542.2, 543.88], "text": " you're also looking for a storage system"}, {"speaker": "SPEAKER_00", "timestamp": [543.88, 545.1], "text": " that can be platform agnostic"}, {"speaker": "SPEAKER_00", "timestamp": [545.1, 551.62], "text": " and work across all of those different platforms too. And finally, and I know this is a little"}, {"speaker": "SPEAKER_00", "timestamp": [551.62, 557.22], "text": " cliched, but I'll go as far as saying, you know, you want to look at the agility of the storage"}, {"speaker": "SPEAKER_00", "timestamp": [557.22, 562.68], "text": " system too. So it's one of the things that needs to be considered because Kubernetes environments"}, {"speaker": "SPEAKER_00", "timestamp": [562.68, 565.22], "text": " tends to be more dynamic."}, {"speaker": "SPEAKER_00", "timestamp": [567.7, 569.28], "text": " They are designed to be dynamically scaled and dynamically upgraded,"}, {"speaker": "SPEAKER_00", "timestamp": [569.56, 571.06], "text": " and therefore nodes come and go"}, {"speaker": "SPEAKER_00", "timestamp": [571.06, 573.84], "text": " and nodes are scaled up and scaled down."}, {"speaker": "SPEAKER_00", "timestamp": [574.52, 576.88], "text": " So you want a storage system that can adapt"}, {"speaker": "SPEAKER_00", "timestamp": [576.88, 580.1], "text": " to the changing nature of the Kubernetes environment."}, {"speaker": "SPEAKER_00", "timestamp": [582.26, 585.16], "text": " And then finally, this is kind of obvious, right?"}, {"speaker": "SPEAKER_00", "timestamp": [585.16, 592.06], "text": " The people are deploying the automation and using Kubernetes to automate everything with"}, {"speaker": "SPEAKER_00", "timestamp": [592.06, 593.62], "text": " their infrastructure, right?"}, {"speaker": "SPEAKER_00", "timestamp": [593.62, 598.24], "text": " And make it predictable and recreateable."}, {"speaker": "SPEAKER_00", "timestamp": [598.24, 604.22], "text": " So this kind of feeds on the concept of cattle versus pets too."}, {"speaker": "SPEAKER_00", "timestamp": [604.22, 606.88], "text": " That said, because we're looking to automate everything"}, {"speaker": "SPEAKER_00", "timestamp": [606.88, 608.44], "text": " within the infrastructure,"}, {"speaker": "SPEAKER_00", "timestamp": [608.84, 612.3], "text": " we also want to make sure that the automation applies"}, {"speaker": "SPEAKER_00", "timestamp": [612.3, 613.6], "text": " to the storage environment"}, {"speaker": "SPEAKER_00", "timestamp": [613.6, 616.58], "text": " and that the storage environment is consistently available"}, {"speaker": "SPEAKER_00", "timestamp": [616.58, 620.34], "text": " and sort of protects the data within your Kubernetes cluster"}, {"speaker": "SPEAKER_00", "timestamp": [620.34, 623.84], "text": " and can also provide the appropriate levels"}, {"speaker": "SPEAKER_00", "timestamp": [623.84, 626.52], "text": " of performance and security that interact"}, {"speaker": "SPEAKER_00", "timestamp": [626.52, 628.48], "text": " with the Kubernetes environment."}, {"speaker": "SPEAKER_00", "timestamp": [628.48, 637.5], "text": " So predictable, deterministic performance and security that natively works with Kubernetes"}, {"speaker": "SPEAKER_00", "timestamp": [637.5, 644.82], "text": " access controls and Kubernetes namespaces, for example, are strong attributes that you"}, {"speaker": "SPEAKER_00", "timestamp": [644.82, 645.76], "text": " should be looking out for."}, {"speaker": "SPEAKER_00", "timestamp": [649.04, 656.96], "text": " So I'm going to move into talking next about the CNCF storage landscape white paper."}, {"speaker": "SPEAKER_00", "timestamp": [659.6, 669.72], "text": " The storage landscape white paper is a document that we started working on now probably about 18, 24 months back."}, {"speaker": "SPEAKER_00", "timestamp": [670.46, 675.54], "text": " And we've had contributions and lots of reviews on the document."}, {"speaker": "SPEAKER_00", "timestamp": [676.48, 688.5], "text": " And what we've tried to do here is we've tried to explain the different components and different attributes of a storage system, covering where a storage"}, {"speaker": "SPEAKER_00", "timestamp": [688.5, 694.12], "text": " system can be deployed, the various attributes of the storage system, the layers and the topology"}, {"speaker": "SPEAKER_00", "timestamp": [694.12, 700.78], "text": " within a storage system, as well as how you access storage and the management interfaces"}, {"speaker": "SPEAKER_00", "timestamp": [700.78, 709.84], "text": " that are used on the control plane for those storage systems. So the reason why this is important is because storage is a very broad topic,"}, {"speaker": "SPEAKER_00", "timestamp": [709.84, 716.8], "text": " right? So we tend to think of storage traditionally as volumes,"}, {"speaker": "SPEAKER_00", "timestamp": [716.8, 723.24], "text": " but in a cloud-native world, storage is any way you can persist data. So in"}, {"speaker": "SPEAKER_00", "timestamp": [723.24, 729.14], "text": " the cloud-native world, you kind of have two types of methods of doing that."}, {"speaker": "SPEAKER_00", "timestamp": [729.28, 735.46], "text": " One is with traditional volumes and one is sort of API based methods, which includes things like"}, {"speaker": "SPEAKER_00", "timestamp": [735.46, 742.24], "text": " object stores and databases and key value stores, for example. And more than ever before, it's"}, {"speaker": "SPEAKER_00", "timestamp": [742.24, 750.5], "text": " becoming really important for developers to understand the storage attributes of their system and to understand how the storage system works."}, {"speaker": "SPEAKER_00", "timestamp": [750.5, 759.54], "text": " Because they need to ensure that those attributes match to what their application requires."}, {"speaker": "SPEAKER_00", "timestamp": [760.22, 762.62], "text": " So we'll talk a little bit about the attributes in a second."}, {"speaker": "SPEAKER_00", "timestamp": [762.62, 763.54], "text": " So we'll talk a little bit about the attributes in a second."}, {"speaker": "SPEAKER_00", "timestamp": [770.42, 771.62], "text": " The first point is there are lots of different ways of deploying storage within an environment, right?"}, {"speaker": "SPEAKER_00", "timestamp": [778.5, 778.98], "text": " The more traditional hardware solutions are typically deployed in a data center."}, {"speaker": "SPEAKER_00", "timestamp": [787.9, 795.2], "text": " But obviously, some of those solutions have limitations on the portability and the use of those solutions within cloud environments. Software solutions tend to be more platform agnostic, and some"}, {"speaker": "SPEAKER_00", "timestamp": [795.2, 801.36], "text": " software solutions and some of the projects that we're looking at in both commercial vendors"}, {"speaker": "SPEAKER_00", "timestamp": [801.36, 806.66], "text": " and CNCF projects, you have software solutions that can be"}, {"speaker": "SPEAKER_00", "timestamp": [806.66, 811.46], "text": " deployed as a container and the deployment can actually be automated"}, {"speaker": "SPEAKER_00", "timestamp": [811.46, 817.38], "text": " through an orchestrator too. And finally of course there are storage services"}, {"speaker": "SPEAKER_00", "timestamp": [817.38, 826.42], "text": " which can be consumed from the public cloud providers. So public cloud providers provide services like object stores or disk"}, {"speaker": "SPEAKER_00", "timestamp": [826.42, 836.16], "text": " volumes too. So we talked a little bit about the storage attributes, but why is it important"}, {"speaker": "SPEAKER_00", "timestamp": [836.16, 847.64], "text": " to understand what these different storage attributes mean? So when we drew up the landscape white paper, we classified the attributes into five different"}, {"speaker": "SPEAKER_00", "timestamp": [847.64, 849.18], "text": " main types."}, {"speaker": "SPEAKER_00", "timestamp": [849.18, 856.4], "text": " Availability, scalability, performance, consistency, and durability."}, {"speaker": "SPEAKER_00", "timestamp": [856.4, 861.0], "text": " What we found was, as we were discussing these different attributes, is that each of these"}, {"speaker": "SPEAKER_00", "timestamp": [861.0, 865.92], "text": " attributes are important to different aspects of an application. So for example,"}, {"speaker": "SPEAKER_00", "timestamp": [867.12, 873.68], "text": " most applications have architecture patterns that depend on a storage subsystem to provide"}, {"speaker": "SPEAKER_00", "timestamp": [873.68, 878.72], "text": " a layer of availability. So if an application needs to move between nodes or failover,"}, {"speaker": "SPEAKER_00", "timestamp": [879.36, 883.6], "text": " it needs to be able to continue to access the same data, for example."}, {"speaker": "SPEAKER_00", "timestamp": [883.62, 892.12], "text": " be able to continue to access the same data, for example. Similarly, another lever or another aspect that is very important for some applications"}, {"speaker": "SPEAKER_00", "timestamp": [892.12, 893.88], "text": " is scalability."}, {"speaker": "SPEAKER_00", "timestamp": [893.88, 898.72], "text": " Now, scalability, again, can be measured in a number of different ways."}, {"speaker": "SPEAKER_00", "timestamp": [898.72, 904.12], "text": " It could be the scalability of the number of operations or the throughput of that environment,"}, {"speaker": "SPEAKER_00", "timestamp": [904.12, 910.18], "text": " or it could be things like the scalability of the number of concurrent clients, for example, that can connect"}, {"speaker": "SPEAKER_00", "timestamp": [910.18, 916.26], "text": " into the system, or indeed the number of components. So does the system scale horizontally"}, {"speaker": "SPEAKER_00", "timestamp": [916.26, 922.78], "text": " or does it scale vertically, for example? Similarly, we talked about deterministic"}, {"speaker": "SPEAKER_00", "timestamp": [922.78, 929.22], "text": " performance, and often performance is one of the key measures of a storage system that people want to understand."}, {"speaker": "SPEAKER_00", "timestamp": [930.22, 945.0], "text": " But again, most storage system topologies have a number of compromises, and they are typically optimized for some combination of different performance parameters."}, {"speaker": "SPEAKER_00", "timestamp": [945.72, 951.54], "text": " So what we see is we see some storage systems, for example, that are highly optimized for"}, {"speaker": "SPEAKER_00", "timestamp": [951.54, 959.14], "text": " low latency and are suitable, for example, for transactional systems, which require that"}, {"speaker": "SPEAKER_00", "timestamp": [959.14, 966.44], "text": " low latency per operation, whereas other storage systems are optimized for throughput, for example,"}, {"speaker": "SPEAKER_00", "timestamp": [967.0, 971.76], "text": " for things like data analytics or data warehousing type operations."}, {"speaker": "SPEAKER_00", "timestamp": [974.16, 978.92], "text": " When we talk about compromises and optimizations of the different storage systems, the other"}, {"speaker": "SPEAKER_00", "timestamp": [978.92, 991.58], "text": " aspect to keep in mind is the consistency. So most systems will have some level of, you know,"}, {"speaker": "SPEAKER_00", "timestamp": [991.64, 994.1], "text": " different levers on the consistency attributes"}, {"speaker": "SPEAKER_00", "timestamp": [994.1, 998.24], "text": " that dramatically affect availability, scalability, and performance."}, {"speaker": "SPEAKER_00", "timestamp": [998.88, 1000.82], "text": " And consistency is measured in two vectors."}, {"speaker": "SPEAKER_00", "timestamp": [1000.82, 1009.84], "text": " One is the amount of time that it takes to commit the data to non-volatile storage"}, {"speaker": "SPEAKER_00", "timestamp": [1010.64, 1016.96], "text": " once it's been committed. And the second is the delay once that data has been committed to be"}, {"speaker": "SPEAKER_00", "timestamp": [1016.96, 1022.16], "text": " able to access that consistently across all the different nodes in a cluster, right? And you'll"}, {"speaker": "SPEAKER_00", "timestamp": [1022.16, 1026.96], "text": " find that some applications can tolerate eventual consistency"}, {"speaker": "SPEAKER_00", "timestamp": [1026.96, 1031.94], "text": " and some applications need very strong synchronous consistency."}, {"speaker": "SPEAKER_00", "timestamp": [1033.52, 1037.08], "text": " And then finally, we look at durability, right?"}, {"speaker": "SPEAKER_00", "timestamp": [1037.08, 1042.68], "text": " And durability sometimes gets confused with availability,"}, {"speaker": "SPEAKER_00", "timestamp": [1043.52, 1047.04], "text": " but they are fundamentally different things. So availability"}, {"speaker": "SPEAKER_00", "timestamp": [1047.04, 1052.56], "text": " is talking about the ability of storage to fail over and to move between nodes and to provide"}, {"speaker": "SPEAKER_00", "timestamp": [1052.56, 1061.12], "text": " some level of redundancy. The durability is a measure of the way that the data is protected"}, {"speaker": "SPEAKER_00", "timestamp": [1061.12, 1068.08], "text": " on the back end in the system, and that includes redundancy. But it also includes"}, {"speaker": "SPEAKER_00", "timestamp": [1068.08, 1071.04], "text": " additional measures like, for example, the way the storage system"}, {"speaker": "SPEAKER_00", "timestamp": [1071.68, 1075.68], "text": " protects against corruption on the underlying disk media, for example."}, {"speaker": "SPEAKER_00", "timestamp": [1079.04, 1097.56], "text": " So we move on then to the storage layers within a storage system. So in a storage system, it's now more common than ever that a typical environment will be composed of a number of different layers."}, {"speaker": "SPEAKER_00", "timestamp": [1098.32, 1103.68], "text": " And some of the layers can be intermingled from different systems."}, {"speaker": "SPEAKER_00", "timestamp": [1103.68, 1104.24], "text": " can be intermingled from different systems."}, {"speaker": "SPEAKER_00", "timestamp": [1109.38, 1109.46], "text": " So it's not uncommon to find different storage systems,"}, {"speaker": "SPEAKER_00", "timestamp": [1111.18, 1113.7], "text": " for example, layers on top of each other to provide different services or different functionality."}, {"speaker": "SPEAKER_00", "timestamp": [1114.8, 1120.82], "text": " At the very top, you have the work that the orchestrator is doing,"}, {"speaker": "SPEAKER_00", "timestamp": [1121.3, 1124.04], "text": " things like virtualizing the mount points"}, {"speaker": "SPEAKER_00", "timestamp": [1124.04, 1125.28], "text": " and making sure that mount points"}, {"speaker": "SPEAKER_00", "timestamp": [1126.08, 1133.76], "text": " are available on different nodes within a cluster and the integration into things like"}, {"speaker": "SPEAKER_00", "timestamp": [1133.76, 1143.84], "text": " namespaces and the container bind lines for example. Another factor to consider within"}, {"speaker": "SPEAKER_00", "timestamp": [1145.38, 1148.36], "text": " to consider within the storage layers is the topology that the storage systems use."}, {"speaker": "SPEAKER_00", "timestamp": [1149.44, 1151.22], "text": " There are storage systems"}, {"speaker": "SPEAKER_00", "timestamp": [1151.22, 1154.0], "text": " that have a very centralized topology,"}, {"speaker": "SPEAKER_00", "timestamp": [1154.44, 1156.54], "text": " perhaps because they have"}, {"speaker": "SPEAKER_00", "timestamp": [1156.54, 1159.22], "text": " some proprietary hardware interconnects"}, {"speaker": "SPEAKER_00", "timestamp": [1159.22, 1162.52], "text": " or they're designed for scaling vertically."}, {"speaker": "SPEAKER_00", "timestamp": [1163.86, 1167.04], "text": " And those sort of systems tend to be optimized"}, {"speaker": "SPEAKER_00", "timestamp": [1167.04, 1169.54], "text": " for performance and low latency,"}, {"speaker": "SPEAKER_00", "timestamp": [1169.7, 1171.32], "text": " but obviously they have the complexity"}, {"speaker": "SPEAKER_00", "timestamp": [1171.32, 1175.42], "text": " of only being able to scale vertically."}, {"speaker": "SPEAKER_00", "timestamp": [1175.98, 1179.36], "text": " You then move into distributed systems,"}, {"speaker": "SPEAKER_00", "timestamp": [1179.36, 1184.36], "text": " which tends to provide much better scaling capabilities"}, {"speaker": "SPEAKER_00", "timestamp": [1184.92, 1189.2], "text": " by scaling horizontally rather than vertically."}, {"speaker": "SPEAKER_00", "timestamp": [1189.98, 1197.6], "text": " But distributed systems then have additional complexity and additional latency requirements"}, {"speaker": "SPEAKER_00", "timestamp": [1197.6, 1203.26], "text": " that need to be taken into consideration because the data is spread out across more nodes"}, {"speaker": "SPEAKER_00", "timestamp": [1203.26, 1206.9], "text": " and therefore across more network connectivity is important."}, {"speaker": "SPEAKER_00", "timestamp": [1208.02, 1214.18], "text": " And then there are also technologies which often apply to databases called sharding, for example,"}, {"speaker": "SPEAKER_00", "timestamp": [1214.58, 1224.4], "text": " where scaling and distribution of data is done by filtering the data into different buckets"}, {"speaker": "SPEAKER_00", "timestamp": [1224.4, 1227.12], "text": " and placing different buckets on different"}, {"speaker": "SPEAKER_00", "timestamp": [1227.12, 1228.12], "text": " systems."}, {"speaker": "SPEAKER_00", "timestamp": [1228.12, 1233.2], "text": " And the last topology I'd like to talk about is hyperconverged, which is something that's"}, {"speaker": "SPEAKER_00", "timestamp": [1233.2, 1236.78], "text": " becoming a bit more common nowadays."}, {"speaker": "SPEAKER_00", "timestamp": [1236.78, 1249.04], "text": " And what we're talking about here is an environment where nodes are simultaneously providing storage to a storage subsystem and used to provide"}, {"speaker": "SPEAKER_00", "timestamp": [1250.8, 1256.48], "text": " storage capacity whilst also running applications and compute capabilities."}, {"speaker": "SPEAKER_00", "timestamp": [1258.16, 1263.12], "text": " The next layer down talks about the way the data is protected within those systems."}, {"speaker": "SPEAKER_00", "timestamp": [1264.12, 1266.96], "text": " at the way the data is protected within those systems. We have things like traditional systems"}, {"speaker": "SPEAKER_00", "timestamp": [1266.96, 1270.72], "text": " that might use some form of RAID,"}, {"speaker": "SPEAKER_00", "timestamp": [1270.72, 1275.36], "text": " which effectively creates parity or mirrors for the data."}, {"speaker": "SPEAKER_00", "timestamp": [1275.36, 1277.24], "text": " More commonly in distributed systems,"}, {"speaker": "SPEAKER_00", "timestamp": [1277.24, 1279.08], "text": " we see erasure coding,"}, {"speaker": "SPEAKER_00", "timestamp": [1279.08, 1281.56], "text": " which again is a way of creating,"}, {"speaker": "SPEAKER_00", "timestamp": [1281.56, 1284.16], "text": " of splitting the data into multiple components"}, {"speaker": "SPEAKER_00", "timestamp": [1284.16, 1285.86], "text": " and creating multiple"}, {"speaker": "SPEAKER_00", "timestamp": [1285.86, 1295.84], "text": " fragments of parity and data that can be used to recover the data if any individual nodes"}, {"speaker": "SPEAKER_00", "timestamp": [1295.84, 1296.42], "text": " goes down."}, {"speaker": "SPEAKER_00", "timestamp": [1297.6, 1303.48], "text": " And then we have the concept of replicas, which where data is replicated in its entirety"}, {"speaker": "SPEAKER_00", "timestamp": [1303.48, 1305.26], "text": " to a number of different nodes."}, {"speaker": "SPEAKER_00", "timestamp": [1306.6, 1316.12], "text": " And often this is a big sort of play between performance, data protection, and availability and durability."}, {"speaker": "SPEAKER_00", "timestamp": [1316.12, 1322.78], "text": " So things like erasure coding provides amazing durability, but typically at a latency cost."}, {"speaker": "SPEAKER_00", "timestamp": [1322.78, 1323.7], "text": " but typically at a latency cost."}, {"speaker": "SPEAKER_00", "timestamp": [1329.2, 1329.44], "text": " And things like replicas provide a lower latency solution,"}, {"speaker": "SPEAKER_00", "timestamp": [1332.3, 1333.32], "text": " but typically at the cost of using additional capacity."}, {"speaker": "SPEAKER_00", "timestamp": [1336.98, 1341.0], "text": " Now, one thing that mustn't be forgotten is the concept that every storage system also provides some layer of data services."}, {"speaker": "SPEAKER_00", "timestamp": [1341.3, 1344.82], "text": " So things like replication of data or snapshots or clones,"}, {"speaker": "SPEAKER_00", "timestamp": [1346.0, 1352.74], "text": " which are point-in-time copies of data services. So things like replication of data or snapshots or clones, which are point in time copies of data, which are typically important for different workflows, whether it's, you know,"}, {"speaker": "SPEAKER_00", "timestamp": [1352.78, 1358.88], "text": " providing disaster recovery or business continuity, or providing backup functionality"}, {"speaker": "SPEAKER_00", "timestamp": [1358.88, 1366.16], "text": " in your system. And we can't forget the physical or the non-volatile layer, right? So,"}, {"speaker": "SPEAKER_00", "timestamp": [1367.76, 1376.24], "text": " you know, from traditional spinning media to fast solid-state devices and moving forward to"}, {"speaker": "SPEAKER_00", "timestamp": [1376.24, 1381.44], "text": " non-volatile, you know, memory class type components, each of those components offer"}, {"speaker": "SPEAKER_00", "timestamp": [1382.16, 1387.2], "text": " a variety of different storage attributes when it comes to,"}, {"speaker": "SPEAKER_00", "timestamp": [1387.2, 1391.2], "text": " you know, obviously performance, but also more importantly things like durability too."}, {"speaker": "SPEAKER_00", "timestamp": [1394.88, 1403.44], "text": " One of the things that's quite interesting is we try to put a table in place to"}, {"speaker": "SPEAKER_00", "timestamp": [1404.4, 1408.64], "text": " compare the different storage topologies between local, remote, and"}, {"speaker": "SPEAKER_00", "timestamp": [1408.64, 1416.8], "text": " distributed systems. And we kind of see that the topology comparison affects each of those storage"}, {"speaker": "SPEAKER_00", "timestamp": [1416.8, 1425.2], "text": " attributes by quite an amount, right? So local systems, for example, are limited in availability,"}, {"speaker": "SPEAKER_00", "timestamp": [1425.2, 1429.36], "text": " whereas remote and distributed systems have better availability and better scalability."}, {"speaker": "SPEAKER_00", "timestamp": [1430.88, 1439.76], "text": " But of course, performance tends to be lower in local systems. And we'll talk a little bit about"}, {"speaker": "SPEAKER_00", "timestamp": [1439.76, 1446.12], "text": " state of locality in a minute. But obviously remote and distributed systems tend to have slightly higher latencies."}, {"speaker": "SPEAKER_00", "timestamp": [1449.22, 1453.22], "text": " So we move on then to the data access interfaces."}, {"speaker": "SPEAKER_00", "timestamp": [1453.22, 1456.46], "text": " And we talked a little bit earlier on"}, {"speaker": "SPEAKER_00", "timestamp": [1456.46, 1460.88], "text": " about the concept of volumes and APIs, right?"}, {"speaker": "SPEAKER_00", "timestamp": [1461.26, 1464.22], "text": " So it's really important to distinguish"}, {"speaker": "SPEAKER_00", "timestamp": [1464.94, 1467.28], "text": " between the data access interface,"}, {"speaker": "SPEAKER_00", "timestamp": [1467.44, 1474.74], "text": " which is what a container or an application uses to actually access the data, and the control"}, {"speaker": "SPEAKER_00", "timestamp": [1474.74, 1489.38], "text": " plane that the orchestrator uses to do things like dynamic provisioning of volumes or management of the storage system. So it's probably fair to say that the most mature APIs"}, {"speaker": "SPEAKER_00", "timestamp": [1490.44, 1493.38], "text": " that are available today with Kubernetes integration"}, {"speaker": "SPEAKER_00", "timestamp": [1493.38, 1494.86], "text": " are volumes."}, {"speaker": "SPEAKER_00", "timestamp": [1494.86, 1497.2], "text": " So things like block devices, file systems"}, {"speaker": "SPEAKER_00", "timestamp": [1497.2, 1498.84], "text": " and shared file systems."}, {"speaker": "SPEAKER_00", "timestamp": [1500.52, 1510.72], "text": " And a lot of databases or message queues or instrumentation like Prometheus, for example, will depend on being able to use these sorts of volumes."}, {"speaker": "SPEAKER_00", "timestamp": [1511.56, 1526.72], "text": " But likewise, of course, there are a whole suite of storage systems that provide object store interfaces or key value stores or databases that are accessed over an API. And those sorts of systems, for example,"}, {"speaker": "SPEAKER_00", "timestamp": [1529.2, 1532.56], "text": " will typically be using that API over a network."}, {"speaker": "SPEAKER_00", "timestamp": [1538.0, 1551.36], "text": " Each of the different data access interfaces are typically suited to different sets of attributes. So what I'm going to do,"}, {"speaker": "SPEAKER_00", "timestamp": [1552.0, 1557.6], "text": " what I'm going to let that settle in for a second and you can see some of the comparisons on the"}, {"speaker": "SPEAKER_00", "timestamp": [1557.6, 1573.2], "text": " screen. So for example, you know, you typically expect block systems to perhaps have a lower latency or file systems to be able to provide the ability to share workloads across multiple nodes, for example."}, {"speaker": "SPEAKER_00", "timestamp": [1573.2, 1579.56], "text": " And object stores are well known for being able to scale to very large capacities, for example."}, {"speaker": "SPEAKER_00", "timestamp": [1589.96, 1590.8], "text": " But that said, one word of caution that caveats all of this is that, you know, we go back to the storage topologies and the layering."}, {"speaker": "SPEAKER_00", "timestamp": [1595.88, 1609.44], "text": " We often have to try and understand what is happening within a storage system, right? So sometimes if you have block devices, which are typically, you know, linked to, for example, a physical low latency device in the server."}, {"speaker": "SPEAKER_01", "timestamp": [1610.56, 1616.56], "text": " Block systems can now, block devices can now work remotely and can work on distributed storage"}, {"speaker": "SPEAKER_00", "timestamp": [1616.56, 1626.4], "text": " systems and therefore they inherit the storage attributes of that distributed system. Similarly, for example, there are"}, {"speaker": "SPEAKER_00", "timestamp": [1626.4, 1632.46], "text": " many file systems that are built on an object store backend and therefore they"}, {"speaker": "SPEAKER_00", "timestamp": [1632.46, 1637.32], "text": " have the, you know, they inherit the latency and the availability and"}, {"speaker": "SPEAKER_00", "timestamp": [1637.32, 1641.54], "text": " durability of the object store rather than just the"}, {"speaker": "SPEAKER_00", "timestamp": [1641.54, 1646.6], "text": " attributes of the file system. So understanding the layering is fairly important"}, {"speaker": "SPEAKER_00", "timestamp": [1646.6, 1649.04], "text": " when we're trying to look at these comparisons."}, {"speaker": "SPEAKER_00", "timestamp": [1651.62, 1655.46], "text": " And then we move on to the orchestration and management interfaces."}, {"speaker": "SPEAKER_00", "timestamp": [1655.82, 1658.86], "text": " So this is how things like dynamic provisioning work"}, {"speaker": "SPEAKER_00", "timestamp": [1658.86, 1661.4], "text": " between Kubernetes and the storage system."}, {"speaker": "SPEAKER_00", "timestamp": [1661.4, 1667.02], "text": " So the container orchestrator of Kubernetes has a control plane interface."}, {"speaker": "SPEAKER_00", "timestamp": [1667.28, 1669.02], "text": " There are a number of these interfaces"}, {"speaker": "SPEAKER_00", "timestamp": [1669.02, 1672.96], "text": " and they talk to the control plane in the storage system."}, {"speaker": "SPEAKER_00", "timestamp": [1673.26, 1675.12], "text": " Now, in some cases,"}, {"speaker": "SPEAKER_00", "timestamp": [1675.12, 1681.42], "text": " the storage system supports the control plane APIs natively."}, {"speaker": "SPEAKER_00", "timestamp": [1682.5, 1683.48], "text": " And in some cases,"}, {"speaker": "SPEAKER_00", "timestamp": [1684.3, 1689.84], "text": " the orchestrator is talking via a framework or a set of tools"}, {"speaker": "SPEAKER_00", "timestamp": [1690.4, 1696.96], "text": " to provide the bridge between the orchestrator API and the storage system API."}, {"speaker": "SPEAKER_00", "timestamp": [1698.0, 1709.4], "text": " Of course, as we discussed before, the workloads talk to the data plane via the data access interface, which is very separate from the control plane interfaces."}, {"speaker": "SPEAKER_00", "timestamp": [1710.18, 1715.56], "text": " So you might ask, OK, we've listed a number of different control plane interfaces, but what do they all mean?"}, {"speaker": "SPEAKER_00", "timestamp": [1716.28, 1720.54], "text": " So the key interface here is the container storage interface."}, {"speaker": "SPEAKER_00", "timestamp": [1721.36, 1728.28], "text": " The container storage interface is similar to CNI for networking or CRI for"}, {"speaker": "SPEAKER_00", "timestamp": [1728.28, 1737.52], "text": " the runtime. It is a standard API which was adopted between orchestrators like Kubernetes"}, {"speaker": "SPEAKER_00", "timestamp": [1737.52, 1748.28], "text": " and different storage vendors. So currently there are, I actually lost track, but there's easily 50 or more storage systems"}, {"speaker": "SPEAKER_00", "timestamp": [1748.28, 1750.08], "text": " that support the CSI interface"}, {"speaker": "SPEAKER_00", "timestamp": [1750.08, 1752.94], "text": " that integrate with Kubernetes."}, {"speaker": "SPEAKER_00", "timestamp": [1754.38, 1760.64], "text": " I'm highlighting CSI because this is the factor standard"}, {"speaker": "SPEAKER_00", "timestamp": [1760.64, 1766.8], "text": " for interfacing Kubernetes to different storage systems and different storage services."}, {"speaker": "SPEAKER_00", "timestamp": [1767.52, 1773.08], "text": " In the past, we had drivers that were mainlined into the Kubernetes source,"}, {"speaker": "SPEAKER_00", "timestamp": [1773.7, 1787.64], "text": " and we had the concept of Kubernetes flex volumes. But if you're trying to implement a new system nowadays, it's probably worth focusing entirely on CSI"}, {"speaker": "SPEAKER_00", "timestamp": [1787.64, 1790.84], "text": " because that's the standard where all the development"}, {"speaker": "SPEAKER_00", "timestamp": [1790.84, 1794.14], "text": " and advancements are happening today."}, {"speaker": "SPEAKER_00", "timestamp": [1798.6, 1800.72], "text": " So we'll talk a little bit now"}, {"speaker": "SPEAKER_01", "timestamp": [1800.72, 1804.2], "text": " about how storage is configured in Kubernetes."}, {"speaker": "SPEAKER_00", "timestamp": [1804.74, 1806.08], "text": " So now that we talked about and"}, {"speaker": "SPEAKER_01", "timestamp": [1806.08, 1811.28], "text": " we kind of set the scene of the storage system with all these different layers and different"}, {"speaker": "SPEAKER_00", "timestamp": [1811.28, 1817.36], "text": " data access methods and different control plane access methods, what does this actually translate"}, {"speaker": "SPEAKER_00", "timestamp": [1817.36, 1826.18], "text": " to in real life and how do these systems interact with Kubernetes?"}, {"speaker": "SPEAKER_00", "timestamp": [1832.12, 1837.5], "text": " So we'll talk a little bit first about the concept of dynamic provisioning. So you remember when we said storage needs to be application-centric,"}, {"speaker": "SPEAKER_00", "timestamp": [1838.26, 1845.4], "text": " and therefore that enables self-service and declarative and composable storage."}, {"speaker": "SPEAKER_00", "timestamp": [1846.16, 1849.08], "text": " How is this actually achieved?"}, {"speaker": "SPEAKER_00", "timestamp": [1849.08, 1855.62], "text": " So the main abstraction layer here is called a storage class."}, {"speaker": "SPEAKER_00", "timestamp": [1856.5, 1865.0], "text": " So effectively, a storage class is a definition that specifies a driver interface,"}, {"speaker": "SPEAKER_00", "timestamp": [1866.36, 1868.58], "text": " typically through CSI,"}, {"speaker": "SPEAKER_00", "timestamp": [1868.58, 1873.58], "text": " that driver interface will be used by the storage system"}, {"speaker": "SPEAKER_00", "timestamp": [1874.5, 1876.9], "text": " to provide and manage the storage, right?"}, {"speaker": "SPEAKER_00", "timestamp": [1876.9, 1880.88], "text": " And this is in relation to dynamically provisioning"}, {"speaker": "SPEAKER_00", "timestamp": [1880.88, 1884.62], "text": " the storage, but also things like attaching storage"}, {"speaker": "SPEAKER_00", "timestamp": [1884.62, 1886.62], "text": " to physical nodes or"}, {"speaker": "SPEAKER_00", "timestamp": [1886.62, 1892.6], "text": " to nodes within the cluster and mounting that storage and managing the storage lifecycle."}, {"speaker": "SPEAKER_00", "timestamp": [1892.6, 1898.0], "text": " So that's all well and good, but what does a storage class really look like? So a storage"}, {"speaker": "SPEAKER_00", "timestamp": [1898.0, 1909.04], "text": " class is actually typically something really, really simple like this. The storage class defines a name. So in this case, we're"}, {"speaker": "SPEAKER_00", "timestamp": [1909.04, 1915.12], "text": " calling it fast because you can create different storage classes for different types of environments."}, {"speaker": "SPEAKER_00", "timestamp": [1916.18, 1924.48], "text": " It might specify some labels or flags that are specific to the storage system. And it"}, {"speaker": "SPEAKER_00", "timestamp": [1924.48, 1926.08], "text": " defines the provisioner."}, {"speaker": "SPEAKER_00", "timestamp": [1926.14, 1929.82], "text": " In this case, we've simplified it and just called it storageOS."}, {"speaker": "SPEAKER_00", "timestamp": [1930.0, 1935.04], "text": " But if we were using CSI, the provisioner would be a CSI provisioner."}, {"speaker": "SPEAKER_01", "timestamp": [1936.78, 1943.6], "text": " What this translates to then is how do developers who want to use"}, {"speaker": "SPEAKER_00", "timestamp": [1943.6, 1949.84], "text": " that composable storage, how do they actually register what they need?"}, {"speaker": "SPEAKER_00", "timestamp": [1949.84, 1956.3], "text": " So the constant here is a persistent volume claim."}, {"speaker": "SPEAKER_00", "timestamp": [1956.3, 1963.04], "text": " So within the definition of your application or your pods,"}, {"speaker": "SPEAKER_00", "timestamp": [1963.04, 1967.68], "text": " you can make a persistent volume claim from the pool of storage"}, {"speaker": "SPEAKER_00", "timestamp": [1967.68, 1975.44], "text": " that's linked to that storage class. Again, what does a persistent volume claim look like?"}, {"speaker": "SPEAKER_00", "timestamp": [1975.44, 1980.4], "text": " Well, fundamentally, it's really, really simple. You give it a name. In this case,"}, {"speaker": "SPEAKER_00", "timestamp": [1980.4, 1986.02], "text": " we're calling it a database volume. You tell it which storage class to use. In this case, we're calling it a database volume. You tell it which storage class to use."}, {"speaker": "SPEAKER_00", "timestamp": [1986.04, 1987.62], "text": " In this case, we're specifying the fast."}, {"speaker": "SPEAKER_00", "timestamp": [1988.8, 1992.28], "text": " And you specify the size of the storage."}, {"speaker": "SPEAKER_00", "timestamp": [1993.34, 1996.6], "text": " I'll talk a little bit about the access modes in a little bit."}, {"speaker": "SPEAKER_00", "timestamp": [1997.8, 2000.32], "text": " But fundamentally, all it is is you say,"}, {"speaker": "SPEAKER_00", "timestamp": [2000.54, 2003.1], "text": " I'm going to give a name to my persistent volume claim."}, {"speaker": "SPEAKER_00", "timestamp": [2003.1, 2011.28], "text": " I'm going to use a particular storage class and it's this amount of capacity. It is also possible to pass things like labels"}, {"speaker": "SPEAKER_00", "timestamp": [2011.28, 2018.0], "text": " which might affect the provisioning capabilities of which might be specific to a particular storage"}, {"speaker": "SPEAKER_00", "timestamp": [2018.0, 2032.2], "text": " system too. What happens then behind the scenes is that Kubernetes talks over the storage interface to the storage system."}, {"speaker": "SPEAKER_00", "timestamp": [2032.8, 2035.64], "text": " The storage system creates a persistent volume."}, {"speaker": "SPEAKER_00", "timestamp": [2036.06, 2043.9], "text": " So we said that the developer makes a claim and the storage system replies by saying, hey, here you are."}, {"speaker": "SPEAKER_00", "timestamp": [2044.3, 2046.16], "text": " This is your persistent volume."}, {"speaker": "SPEAKER_00", "timestamp": [2047.08, 2054.72], "text": " You then reference that claim in the pod. And when your application in the pod is started,"}, {"speaker": "SPEAKER_00", "timestamp": [2055.44, 2064.02], "text": " that persistent volume is connected into the pod. So moving forward a little bit,"}, {"speaker": "SPEAKER_00", "timestamp": [2067.68, 2078.3], "text": " the pods. So moving forward a little bit, what does that actually look like? So this is an example of a simple, you know, an empty pods that just runs a sleep command and uses a PVC1 claim."}, {"speaker": "SPEAKER_00", "timestamp": [2079.04, 2087.84], "text": " So what we see here is when the PVC is requested, the storage system will create the persistent volume like we"}, {"speaker": "SPEAKER_00", "timestamp": [2087.84, 2095.04], "text": " just described, and then that persistent volume is attached to a node and is mounted, typically"}, {"speaker": "SPEAKER_00", "timestamp": [2095.04, 2105.0], "text": " in farlib-kubelet, a long path name in farlib-kubelet. Once that happens and the container is then started,"}, {"speaker": "SPEAKER_00", "timestamp": [2105.0, 2110.0], "text": " that part in the node is bind mounted"}, {"speaker": "SPEAKER_00", "timestamp": [2110.18, 2112.0], "text": " into the specified mount point,"}, {"speaker": "SPEAKER_00", "timestamp": [2112.0, 2114.28], "text": " which in this case is slash MNT"}, {"speaker": "SPEAKER_00", "timestamp": [2114.28, 2116.2], "text": " within the container namespace."}, {"speaker": "SPEAKER_00", "timestamp": [2116.2, 2119.56], "text": " So the application starts and now has access"}, {"speaker": "SPEAKER_00", "timestamp": [2119.56, 2122.8], "text": " to a file system or that volume under,"}, {"speaker": "SPEAKER_00", "timestamp": [2122.8, 2128.24], "text": " in this case, the slash mnt mount point. If that application"}, {"speaker": "SPEAKER_00", "timestamp": [2128.24, 2137.76], "text": " then moves to different nodes within the cluster, the reverse happens. The persistent volume is"}, {"speaker": "SPEAKER_00", "timestamp": [2137.76, 2146.48], "text": " detached and reattached on another node and then remounted and can be reused by an application on the other node."}, {"speaker": "SPEAKER_00", "timestamp": [2150.32, 2156.16], "text": " So if you recall, we talked a little bit about volume access modes too. So in the volume access"}, {"speaker": "SPEAKER_00", "timestamp": [2156.16, 2167.12], "text": " modes, we have two typical modes. One is RedriveOnce and one is Redrive many. So read write once means that the volume is mounted and accessed"}, {"speaker": "SPEAKER_00", "timestamp": [2167.12, 2173.28], "text": " exclusively only by one node. This is this is typically the type of storage that you'd see from"}, {"speaker": "SPEAKER_00", "timestamp": [2173.28, 2182.32], "text": " say block storage services. We also have the read write many and this will typically be used to"}, {"speaker": "SPEAKER_00", "timestamp": [2182.32, 2192.86], "text": " access a shared file system. So so effectively this gives the ability to mount a file system on multiple nodes simultaneously."}, {"speaker": "SPEAKER_00", "timestamp": [2193.74, 2200.34], "text": " And that can be used for different storage patterns, perhaps,"}, {"speaker": "SPEAKER_00", "timestamp": [2200.56, 2207.32], "text": " where a common file system needs to be available to provide a consistent level of config"}, {"speaker": "SPEAKER_00", "timestamp": [2207.32, 2209.08], "text": " or a consistent level of reference data"}, {"speaker": "SPEAKER_00", "timestamp": [2209.08, 2212.08], "text": " to multiple nodes within a system."}, {"speaker": "SPEAKER_00", "timestamp": [2214.06, 2214.9], "text": " Okay."}, {"speaker": "SPEAKER_01", "timestamp": [2218.46, 2221.8], "text": " So what I'm going to do is I'm going to show"}, {"speaker": "SPEAKER_00", "timestamp": [2221.8, 2234.72], "text": " a very, very quick example, assuming everything works, of provisioning a stateful workload and moving a stateful workload from one node to another in a Kubernetes cluster."}, {"speaker": "SPEAKER_01", "timestamp": [2235.54, 2243.42], "text": " For reference, I'm just using one of the simple examples that's available on the StorageOS website."}, {"speaker": "SPEAKER_00", "timestamp": [2244.3, 2247.74], "text": " But obviously, you can run any application"}, {"speaker": "SPEAKER_01", "timestamp": [2247.74, 2250.36], "text": " with any number of different storage systems."}, {"speaker": "SPEAKER_00", "timestamp": [2251.78, 2253.4], "text": " In this particular example,"}, {"speaker": "SPEAKER_00", "timestamp": [2253.64, 2257.66], "text": " I'm going to start up a MySQL database"}, {"speaker": "SPEAKER_00", "timestamp": [2257.66, 2261.42], "text": " and I'm using the free StorageOS developer edition,"}, {"speaker": "SPEAKER_00", "timestamp": [2261.68, 2267.38], "text": " which is free forever and available on our website."}, {"speaker": "SPEAKER_00", "timestamp": [2268.38, 2276.46], "text": " The stateful set definition effectively tells Kubernetes to make a claim for a MySQL database"}, {"speaker": "SPEAKER_00", "timestamp": [2276.46, 2283.62], "text": " and to start it up with Firelib MySQL in the mount part."}, {"speaker": "SPEAKER_00", "timestamp": [2284.28, 2287.08], "text": " So I've already done this."}, {"speaker": "SPEAKER_00", "timestamp": [2287.82, 2296.0], "text": " So what I'm going to do now is I will briefly unshare my screen"}, {"speaker": "SPEAKER_01", "timestamp": [2296.0, 2313.08], "text": " and I will now share my demo."}, {"speaker": "SPEAKER_00", "timestamp": [2318.18, 2319.18], "text": " Sanjeev, can you just confirm that the demo screen is loaded?"}, {"speaker": "SPEAKER_02", "timestamp": [2320.28, 2320.44], "text": " Yes, Alex."}, {"speaker": "SPEAKER_01", "timestamp": [2320.9, 2321.48], "text": " Looks good."}, {"speaker": "SPEAKER_02", "timestamp": [2321.82, 2322.14], "text": " Awesome."}, {"speaker": "SPEAKER_01", "timestamp": [2322.42, 2323.44], "text": " All right."}, {"speaker": "SPEAKER_00", "timestamp": [2328.9, 2330.24], "text": " So I'm going to be using a little tool called K9S"}, {"speaker": "SPEAKER_01", "timestamp": [2333.54, 2337.32], "text": " to provide visibility of what's going on in the cluster. K9S is an open source tool,"}, {"speaker": "SPEAKER_00", "timestamp": [2337.32, 2340.02], "text": " but it's really great at visualizing what's going on"}, {"speaker": "SPEAKER_03", "timestamp": [2340.02, 2341.24], "text": " in the Kubernetes cluster."}, {"speaker": "SPEAKER_00", "timestamp": [2341.24, 2342.56], "text": " One quick one, Alex,"}, {"speaker": "SPEAKER_03", "timestamp": [2342.56, 2345.76], "text": " if you could maybe magnify the font a little bit, that might help."}, {"speaker": "SPEAKER_00", "timestamp": [2347.28, 2355.76], "text": " Right. Is that any better? That's better. Okay, great stuff."}, {"speaker": "SPEAKER_03", "timestamp": [2357.52, 2366.48], "text": " So this is a running cluster. We see the storage OS, storage software is running here,"}, {"speaker": "SPEAKER_01", "timestamp": [2366.52, 2368.8], "text": " as well as the CSI software."}, {"speaker": "SPEAKER_03", "timestamp": [2369.8, 2374.94], "text": " And it's a typical implementation of a Kubernetes cluster."}, {"speaker": "SPEAKER_01", "timestamp": [2375.72, 2378.26], "text": " We'll focus on the application that's running."}, {"speaker": "SPEAKER_00", "timestamp": [2378.26, 2382.56], "text": " So this is the MySQL pod."}, {"speaker": "SPEAKER_00", "timestamp": [2383.2, 2386.16], "text": " So before we move forward,"}, {"speaker": "SPEAKER_00", "timestamp": [2386.16, 2387.76], "text": " what I just want to show is,"}, {"speaker": "SPEAKER_00", "timestamp": [2390.12, 2393.44], "text": " I want to show the pods"}, {"speaker": "SPEAKER_00", "timestamp": [2394.36, 2398.1], "text": " and the YAML for that pods,"}, {"speaker": "SPEAKER_00", "timestamp": [2399.16, 2402.14], "text": " which is running successfully here."}, {"speaker": "SPEAKER_00", "timestamp": [2402.14, 2405.16], "text": " And I want to be able to also and I"}, {"speaker": "SPEAKER_00", "timestamp": [2405.16, 2413.62], "text": " also want to show you the storage class. So we have the"}, {"speaker": "SPEAKER_00", "timestamp": [2413.62, 2420.58], "text": " fast storage class here. And we can describe the storage class,"}, {"speaker": "SPEAKER_01", "timestamp": [2421.46, 2424.38], "text": " which gives you the very simple information to say that this is"}, {"speaker": "SPEAKER_00", "timestamp": [2424.38, 2429.0], "text": " using the CSI API to talk to API to talk to the storage system."}, {"speaker": "SPEAKER_00", "timestamp": [2429.0, 2441.0], "text": " We can look at the PVC. So we have the PVC called data mySQL zero."}, {"speaker": "SPEAKER_00", "timestamp": [2441.0, 2445.88], "text": " And it's connected to this volume."}, {"speaker": "SPEAKER_00", "timestamp": [2445.88, 2448.0], "text": " So we can also see that volume."}, {"speaker": "SPEAKER_00", "timestamp": [2448.0, 2450.4], "text": " We can see the persistent volume here."}, {"speaker": "SPEAKER_00", "timestamp": [2450.4, 2456.68], "text": " So this is the persistent volume that claim is using."}, {"speaker": "SPEAKER_00", "timestamp": [2458.42, 2469.54], "text": " What this means is that we now have MySQL running with a stateful set on our"}, {"speaker": "SPEAKER_00", "timestamp": [2469.54, 2482.98], "text": " cluster on a persistent volume. So as an example I will show you the... we can"}, {"speaker": "SPEAKER_00", "timestamp": [2482.98, 2487.94], "text": " connect to MySQL and quickly show the databases that are currently defined."}, {"speaker": "SPEAKER_00", "timestamp": [2487.94, 2495.48], "text": " This is a blank install. So this is just the stuff that you get on a native, on a startup."}, {"speaker": "SPEAKER_00", "timestamp": [2497.14, 2517.14], "text": " We will run a little bit of SQL to create a database called shop and create the table called books and create a fictional book called CNCF webinar into that database."}, {"speaker": "SPEAKER_00", "timestamp": [2532.02, 2536.92], "text": " And we can now query the database and we can see that there is the table was created and the book CNCF webinar was inserted into the database."}, {"speaker": "SPEAKER_00", "timestamp": [2536.92, 2546.44], "text": " So now what I'm just going to show you is this cluster is running on three nodes."}, {"speaker": "SPEAKER_00", "timestamp": [2557.04, 2558.66], "text": " And the MySQL pod is running on the node name that ends in 3U J9R."}, {"speaker": "SPEAKER_00", "timestamp": [2566.72, 2569.44], "text": " So what I'm going to do now is I'm going to use the Kubernetes cordon command"}, {"speaker": "SPEAKER_00", "timestamp": [2577.2, 2578.4], "text": " to tell Kubernetes that I don't want any new workloads to be scheduled on that node."}, {"speaker": "SPEAKER_00", "timestamp": [2587.36, 2588.16], "text": " And what I am going to do now is I'm going to kill the stateful set that's running on that node. So"}, {"speaker": "SPEAKER_00", "timestamp": [2594.64, 2607.12], "text": " there we go. I've just deleted the pods for that stateful set. Kubernetes is going to see that the pods was killed and needs to reconcile desired states versus actual states. So it's now going in and creating a new instance"}, {"speaker": "SPEAKER_00", "timestamp": [2607.12, 2611.18], "text": " on another node that ends in 3u j9b."}, {"speaker": "SPEAKER_00", "timestamp": [2612.44, 2615.94], "text": " Hopefully that container will start up in a second."}, {"speaker": "SPEAKER_02", "timestamp": [2630.82, 2632.82], "text": " Of course, this is where normally it takes two seconds, and today it's decided to take a little longer."}, {"speaker": "SPEAKER_01", "timestamp": [2632.82, 2639.14], "text": " Alex, a few questions have piled up in the Q&A chat, so if you feel like you want"}, {"speaker": "SPEAKER_02", "timestamp": [2639.14, 2642.24], "text": " to pick what to do at any point."}, {"speaker": "SPEAKER_01", "timestamp": [2642.24, 2643.24], "text": " Okay."}, {"speaker": "SPEAKER_03", "timestamp": [2643.24, 2646.04], "text": " Actually, that's a good thing."}, {"speaker": "SPEAKER_00", "timestamp": [2646.2, 2648.4], "text": " I'll just finish off this demo now"}, {"speaker": "SPEAKER_00", "timestamp": [2648.4, 2650.16], "text": " and we can do that."}, {"speaker": "SPEAKER_00", "timestamp": [2650.5, 2651.82], "text": " So what we can see here is"}, {"speaker": "SPEAKER_00", "timestamp": [2651.82, 2654.18], "text": " that the MySQL instance"}, {"speaker": "SPEAKER_00", "timestamp": [2654.18, 2655.62], "text": " actually has now started"}, {"speaker": "SPEAKER_00", "timestamp": [2655.62, 2657.12], "text": " on another node."}, {"speaker": "SPEAKER_00", "timestamp": [2658.52, 2660.26], "text": " And what we should be able to do"}, {"speaker": "SPEAKER_00", "timestamp": [2660.26, 2662.76], "text": " is we should be able to"}, {"speaker": "SPEAKER_00", "timestamp": [2662.76, 2664.66], "text": " query the database again."}, {"speaker": "SPEAKER_00", "timestamp": [2665.0, 2666.38], "text": " And what we see is we should be able to query the database again."}, {"speaker": "SPEAKER_00", "timestamp": [2671.38, 2671.44], "text": " And what we see is we get the same information back."}, {"speaker": "SPEAKER_00", "timestamp": [2674.96, 2678.24], "text": " So effectively what's happened here is the pod was terminated, Kubernetes restarted"}, {"speaker": "SPEAKER_00", "timestamp": [2678.24, 2683.24], "text": " the stateful set on another node, reconnected the PVC"}, {"speaker": "SPEAKER_00", "timestamp": [2683.4, 2687.22], "text": " and that persistent data was provided there."}, {"speaker": "SPEAKER_00", "timestamp": [2687.22, 2699.38], "text": " So we have a system where using the orchestration capabilities of Kubernetes and the functionality"}, {"speaker": "SPEAKER_00", "timestamp": [2699.38, 2706.1], "text": " of cognitive storage, it's now possible to run stateful services like databases within"}, {"speaker": "SPEAKER_00", "timestamp": [2706.1, 2709.44], "text": " your Kubernetes cluster and incorporate them into your environment."}, {"speaker": "SPEAKER_00", "timestamp": [2710.44, 2716.54], "text": " And it also means that you can now quite easily build anything as a service, right?"}, {"speaker": "SPEAKER_00", "timestamp": [2716.64, 2721.2], "text": " So whether it's a database, a message queue, Prometheus services, Elasticsearch, Kafka,"}, {"speaker": "SPEAKER_00", "timestamp": [2721.32, 2725.92], "text": " whatever that is, you can now run them as a service dynamically within"}, {"speaker": "SPEAKER_00", "timestamp": [2726.8, 2730.72], "text": " your Kubernetes cluster with that persistent storage backend."}, {"speaker": "SPEAKER_02", "timestamp": [2732.16, 2750.18], "text": " So I'll stop sharing that demo and go back to the slides very quickly. Where are we?"}, {"speaker": "SPEAKER_00", "timestamp": [2752.76, 2753.52], "text": " Oh, my slide's closed."}, {"speaker": "SPEAKER_02", "timestamp": [2753.96, 2754.36], "text": " Never mind."}, {"speaker": "SPEAKER_00", "timestamp": [2754.96, 2755.58], "text": " I'll just talk."}, {"speaker": "SPEAKER_02", "timestamp": [2757.54, 2757.76], "text": " I was only going to have a tanky slide up."}, {"speaker": "SPEAKER_00", "timestamp": [2761.94, 2762.62], "text": " So we can go through and answer some of the questions."}, {"speaker": "SPEAKER_02", "timestamp": [2766.48, 2766.9], "text": " So hopefully this provided some useful background."}, {"speaker": "SPEAKER_00", "timestamp": [2768.68, 2768.86], "text": " I tried to make it, you know,"}, {"speaker": "SPEAKER_00", "timestamp": [2771.76, 2771.94], "text": " I only tried to use StorageOS as an example,"}, {"speaker": "SPEAKER_00", "timestamp": [2774.6, 2778.56], "text": " but, you know, hopefully this gave you a broader understanding of the storage landscape."}, {"speaker": "SPEAKER_00", "timestamp": [2778.78, 2783.84], "text": " We'd love you to have a look at the landscape white paper,"}, {"speaker": "SPEAKER_00", "timestamp": [2784.36, 2789.54], "text": " and it would be great to get feedback on that white paper"}, {"speaker": "SPEAKER_00", "timestamp": [2789.54, 2793.08], "text": " because we're about to release the second version that's"}, {"speaker": "SPEAKER_00", "timestamp": [2793.08, 2797.12], "text": " further expanded and updated."}, {"speaker": "SPEAKER_00", "timestamp": [2797.12, 2804.72], "text": " There's a question about the meetups for the CNCF SIG"}, {"speaker": "SPEAKER_00", "timestamp": [2804.72, 2806.08], "text": " and for StorageOS. For the CNCF SIG and for StorageOS."}, {"speaker": "SPEAKER_00", "timestamp": [2806.08, 2809.9], "text": " For the CNCF SIG, we meet twice a month."}, {"speaker": "SPEAKER_00", "timestamp": [2809.9, 2815.24], "text": " The meetings are in the CNCF public calendar."}, {"speaker": "SPEAKER_00", "timestamp": [2815.24, 2818.12], "text": " It's the second Tuesday and the fourth, sorry,"}, {"speaker": "SPEAKER_00", "timestamp": [2818.12, 2823.28], "text": " the second Wednesday and the fourth Wednesday of every month."}, {"speaker": "SPEAKER_00", "timestamp": [2823.28, 2826.38], "text": " We had another question to say,"}, {"speaker": "SPEAKER_00", "timestamp": [2826.38, 2830.48], "text": " can I limit containers to access to spec files"}, {"speaker": "SPEAKER_00", "timestamp": [2830.48, 2834.4], "text": " or inherit the volume settings?"}, {"speaker": "SPEAKER_00", "timestamp": [2835.66, 2838.78], "text": " So I'm gonna try and interpret that question."}, {"speaker": "SPEAKER_00", "timestamp": [2838.78, 2843.78], "text": " So effectively the containers will be using,"}, {"speaker": "SPEAKER_00", "timestamp": [2851.36, 2852.32], "text": " will be using the volumes and the volumes, just like the containers and the pods"}, {"speaker": "SPEAKER_00", "timestamp": [2860.56, 2861.84], "text": " are created within the same concept of the Kubernetes access controls. So things like"}, {"speaker": "SPEAKER_00", "timestamp": [2870.64, 2871.9], "text": " namespaces and access to those namespaces and the filters, et cetera, that apply to those namespaces also apply to the volume abstractions too."}, {"speaker": "SPEAKER_00", "timestamp": [2876.16, 2886.16], "text": " There is a question about Ceph and the Rook operator. So that's a very good example of the concept of having frameworks and tools that are helping or that integrate with the storage system"}, {"speaker": "SPEAKER_00", "timestamp": [2886.16, 2888.64], "text": " to provide the Kubernetes integration."}, {"speaker": "SPEAKER_00", "timestamp": [2888.64, 2893.08], "text": " So, Rook is an operator and it's a framework"}, {"speaker": "SPEAKER_00", "timestamp": [2893.08, 2896.44], "text": " for actually more than one storage system."}, {"speaker": "SPEAKER_00", "timestamp": [2896.44, 2900.24], "text": " It's going through CNCF as a graduation process right now"}, {"speaker": "SPEAKER_00", "timestamp": [2900.24, 2901.24], "text": " in the storage SIG."}, {"speaker": "SPEAKER_00", "timestamp": [2902.32, 2907.08], "text": " And Rook can deploy a Ceph based storage system."}, {"speaker": "SPEAKER_00", "timestamp": [2907.08, 2912.96], "text": " Ceph being a storage system which is fundamentally based on an underlying"}, {"speaker": "SPEAKER_00", "timestamp": [2912.96, 2918.04], "text": " object store, but can provide block and file system semantics too."}, {"speaker": "SPEAKER_00", "timestamp": [2921.12, 2926.0], "text": " Can multiple containers in a single pod share the same PVC?"}, {"speaker": "SPEAKER_00", "timestamp": [2926.62, 2929.62], "text": " So the answer is yes."}, {"speaker": "SPEAKER_00", "timestamp": [2930.36, 2932.24], "text": " There are two ways that this can happen."}, {"speaker": "SPEAKER_00", "timestamp": [2932.74, 2942.34], "text": " If multiple containers within a pod can access the same read-write-once volume,"}, {"speaker": "SPEAKER_00", "timestamp": [2942.52, 2946.56], "text": " if they are on the same node nodes typically. So this is something"}, {"speaker": "SPEAKER_00", "timestamp": [2946.56, 2955.76], "text": " that some storage systems support. However, if you want to follow the storage patterns properly,"}, {"speaker": "SPEAKER_00", "timestamp": [2955.76, 2965.12], "text": " it's best to use the read write many or a shared file system if many containers need to be able to access the same volume."}, {"speaker": "SPEAKER_01", "timestamp": [2972.56, 2979.84], "text": " We had a question to ask if we can provide a little explanation for on-prem storage solutions"}, {"speaker": "SPEAKER_00", "timestamp": [2979.84, 2990.48], "text": " for Kubernetes. So on-prem solutions are quite varied because of course, as we discussed, we have"}, {"speaker": "SPEAKER_01", "timestamp": [2991.04, 2997.28], "text": " some of the traditional storage vendors, so maybe things like traditional physical"}, {"speaker": "SPEAKER_00", "timestamp": [2997.28, 3003.92], "text": " hardware storage array type solutions, some of which have very well integrated"}, {"speaker": "SPEAKER_00", "timestamp": [3009.16, 3010.14], "text": " some of which have very well integrated CSI drivers that can integrate with Kubernetes."}, {"speaker": "SPEAKER_00", "timestamp": [3016.9, 3017.44], "text": " But likewise, there are a whole, you know, there are a suite of software-defined storage systems,"}, {"speaker": "SPEAKER_00", "timestamp": [3024.3, 3030.34], "text": " you know, like StorageOS or Ceph and Rook, for example, that can be deployed on premise too. And, you know, there isn't an answer where I can say,"}, {"speaker": "SPEAKER_00", "timestamp": [3030.46, 3037.16], "text": " you know, this is definitely the storage solution that you should use for on-prem. The reason being,"}, {"speaker": "SPEAKER_00", "timestamp": [3037.26, 3041.96], "text": " you know, as we discussed, is that there is a whole suite of, you know, different attributes"}, {"speaker": "SPEAKER_00", "timestamp": [3041.96, 3048.08], "text": " that you need to look at. And perhaps some decisions that might factor into the process"}, {"speaker": "SPEAKER_00", "timestamp": [3048.08, 3053.34], "text": " might be cost-based or they might be platform compatibility-based."}, {"speaker": "SPEAKER_00", "timestamp": [3053.94, 3058.18], "text": " So, for example, you might find it easier to deploy a software solution"}, {"speaker": "SPEAKER_00", "timestamp": [3058.18, 3062.9], "text": " if you're running environments on-prem and in the cloud"}, {"speaker": "SPEAKER_00", "timestamp": [3062.9, 3063.92], "text": " or some sort of hybrid."}, {"speaker": "SPEAKER_00", "timestamp": [3066.0, 3072.34], "text": " But it's something that you need to understand from your backend system too."}, {"speaker": "SPEAKER_00", "timestamp": [3074.06, 3077.12], "text": " There's a question to ask, is StorageOS a shared file system?"}, {"speaker": "SPEAKER_00", "timestamp": [3078.0, 3080.16], "text": " How does it handle read-writes for multiple nodes?"}, {"speaker": "SPEAKER_00", "timestamp": [3080.16, 3081.78], "text": " And do you handle file logs?"}, {"speaker": "SPEAKER_00", "timestamp": [3081.8, 3082.62], "text": " and you handle file logs."}, {"speaker": "SPEAKER_00", "timestamp": [3085.02, 3088.26], "text": " So what you'll find is that StorageOS can provide both"}, {"speaker": "SPEAKER_00", "timestamp": [3088.26, 3091.08], "text": " read-write-once and read-write-many solutions"}, {"speaker": "SPEAKER_00", "timestamp": [3091.08, 3094.76], "text": " and similar to some of the read-write-many solutions"}, {"speaker": "SPEAKER_00", "timestamp": [3094.76, 3097.8], "text": " they are provided using a shared file system."}, {"speaker": "SPEAKER_00", "timestamp": [3098.9, 3101.94], "text": " So in the case of something like Ceph, for example"}, {"speaker": "SPEAKER_00", "timestamp": [3101.94, 3104.74], "text": " it might use the CephFS file system."}, {"speaker": "SPEAKER_00", "timestamp": [3105.7, 3110.52], "text": " Other storage systems might be using something like NFS,"}, {"speaker": "SPEAKER_00", "timestamp": [3110.52, 3114.6], "text": " for example, as the way of providing the shared file system"}, {"speaker": "SPEAKER_00", "timestamp": [3114.6, 3116.66], "text": " across multiple nodes."}, {"speaker": "SPEAKER_00", "timestamp": [3118.64, 3123.64], "text": " So in terms of how they handle things like file locks"}, {"speaker": "SPEAKER_00", "timestamp": [3124.28, 3128.8], "text": " will be very dependent on the NFS implementation"}, {"speaker": "SPEAKER_00", "timestamp": [3128.8, 3130.66], "text": " of the underlying storage system."}, {"speaker": "SPEAKER_00", "timestamp": [3130.66, 3135.66], "text": " If they're using a modern NFS implementation"}, {"speaker": "SPEAKER_00", "timestamp": [3135.88, 3138.76], "text": " and support things like NFS version four,"}, {"speaker": "SPEAKER_00", "timestamp": [3138.76, 3140.72], "text": " then you should be able to handle state"}, {"speaker": "SPEAKER_00", "timestamp": [3140.72, 3142.18], "text": " and lock failovers too."}, {"speaker": "SPEAKER_00", "timestamp": [3144.5, 3148.04], "text": " Is there work being done to provide a more user-friendly platform with a"}, {"speaker": "SPEAKER_00", "timestamp": [3148.5, 3150.26], "text": " shared file system approach?"}, {"speaker": "SPEAKER_00", "timestamp": [3152.0, 3155.84], "text": " I find it difficult to provide a solution that will work on many platforms and"}, {"speaker": "SPEAKER_00", "timestamp": [3155.84, 3159.82], "text": " clouds. Right. So, so that's, that's a good question."}, {"speaker": "SPEAKER_00", "timestamp": [3159.86, 3164.48], "text": " I think if you're looking to find a solution that will work on many platforms"}, {"speaker": "SPEAKER_00", "timestamp": [3164.48, 3165.28], "text": " and different"}, {"speaker": "SPEAKER_00", "timestamp": [3165.28, 3171.48], "text": " clouds, you should be looking at some of the software-defined storage solutions that are"}, {"speaker": "SPEAKER_00", "timestamp": [3171.48, 3171.88], "text": " out there."}, {"speaker": "SPEAKER_00", "timestamp": [3171.88, 3178.34], "text": " There are a number of CNCF projects that provide software solutions, and there are a number"}, {"speaker": "SPEAKER_00", "timestamp": [3178.34, 3183.74], "text": " of commercial vendors like StorageOS that provide those solutions too."}, {"speaker": "SPEAKER_00", "timestamp": [3181.56, 3183.96], "text": " commercial vendors, you know, like storage, that provide those solutions too."}, {"speaker": "SPEAKER_00", "timestamp": [3184.86, 3187.82], "text": " Software defined solutions typically are,"}, {"speaker": "SPEAKER_00", "timestamp": [3188.94, 3190.96], "text": " typically are platform agnostics."}, {"speaker": "SPEAKER_00", "timestamp": [3190.96, 3195.46], "text": " Although, you know, you may find that different solutions"}, {"speaker": "SPEAKER_00", "timestamp": [3195.46, 3198.7], "text": " might be optimized or might have some caveats"}, {"speaker": "SPEAKER_00", "timestamp": [3198.7, 3201.9], "text": " on different services or different cloud providers"}, {"speaker": "SPEAKER_00", "timestamp": [3201.9, 3203.9], "text": " that they're optimized for that they run."}, {"speaker": "SPEAKER_00", "timestamp": [3206.48, 3211.36], "text": " Can I depend on servers internal SSD was another question. So that's a very, very good question."}, {"speaker": "SPEAKER_00", "timestamp": [3212.16, 3217.52], "text": " And this ties into again the software based solutions. So typically software based solutions"}, {"speaker": "SPEAKER_00", "timestamp": [3217.52, 3226.88], "text": " like storage OS or Rook, for example, can use storage that's available on each node to provide a storage pool that"}, {"speaker": "SPEAKER_00", "timestamp": [3226.88, 3233.2], "text": " effectively spans the different nodes within a cluster. So yes, you can use the Intuendal SSD,"}, {"speaker": "SPEAKER_00", "timestamp": [3233.2, 3239.68], "text": " and effectively the software-defined storage system provides kind of like a storage persona"}, {"speaker": "SPEAKER_00", "timestamp": [3239.68, 3247.44], "text": " to those nodes and allows you to turn those commodity disks or commodity systems into"}, {"speaker": "SPEAKER_00", "timestamp": [3249.2, 3255.36], "text": " a storage service with different data services based on the software solution you're using."}, {"speaker": "SPEAKER_00", "timestamp": [3257.44, 3264.96], "text": " Is there a CSI driver to allow accessing an object store via PVC? So the answer is yes and no."}, {"speaker": "SPEAKER_00", "timestamp": [3271.52, 3280.18], "text": " object store via PVC? So the answer is yes and no. So specifically at PVC, no. The CSI API is focused on providing functionality to access volumes within a system, and those"}, {"speaker": "SPEAKER_00", "timestamp": [3280.18, 3286.64], "text": " volumes typically mean block file or shared file. There are, however, a number of"}, {"speaker": "SPEAKER_00", "timestamp": [3286.64, 3293.32], "text": " discussions which are happening in the Kubernetes storage SIG right now that are talking about"}, {"speaker": "SPEAKER_00", "timestamp": [3293.32, 3301.68], "text": " providing an abstraction to define access to object stores and buckets and things like that"}, {"speaker": "SPEAKER_00", "timestamp": [3301.68, 3305.04], "text": " through a Kubernetes abstraction layer."}, {"speaker": "SPEAKER_00", "timestamp": [3306.04, 3312.24], "text": " So, you know, as I mentioned earlier, volumes are probably the most mature"}, {"speaker": "SPEAKER_00", "timestamp": [3312.24, 3316.36], "text": " abstraction within Kubernetes when it comes to storage, things like object"}, {"speaker": "SPEAKER_00", "timestamp": [3316.36, 3318.24], "text": " stores are happening right now."}, {"speaker": "SPEAKER_00", "timestamp": [3318.24, 3319.92], "text": " So you should follow, watch this space."}, {"speaker": "SPEAKER_00", "timestamp": [3320.36, 3324.36], "text": " And if you're interested in finding out details, join the Kubernetes"}, {"speaker": "SPEAKER_00", "timestamp": [3324.4, 3326.6], "text": " storage SIG mailing lists."}, {"speaker": "SPEAKER_00", "timestamp": [3326.6, 3337.16], "text": " And with that, we are one minute from time and I believe I've covered all of the questions"}, {"speaker": "SPEAKER_00", "timestamp": [3337.16, 3338.86], "text": " in my list here."}, {"speaker": "SPEAKER_02", "timestamp": [3338.86, 3352.44], "text": " Sanjeev, were there any other questions that maybe I missed out on?"}, {"speaker": "SPEAKER_02", "timestamp": [3352.78, 3354.18], "text": " All right."}, {"speaker": "SPEAKER_00", "timestamp": [3357.5, 3363.24], "text": " Well, in that case, I think, I think we're done. So I'd like to say thank you to everybody that joins the webinar."}, {"speaker": "SPEAKER_02", "timestamp": [3363.08, 3364.62], "text": " to everybody that joins the webinar."}, {"speaker": "SPEAKER_00", "timestamp": [3368.78, 3371.62], "text": " And we'll be sharing the information and the slides later on."}, {"speaker": "SPEAKER_00", "timestamp": [3373.84, 3375.58], "text": " Yep. Thank you, Alex."}, {"speaker": "SPEAKER_03", "timestamp": [3376.04, 3377.52], "text": " Thanks for a great presentation."}, {"speaker": "SPEAKER_03", "timestamp": [3377.76, 3378.76], "text": " This was very useful."}, {"speaker": "SPEAKER_03", "timestamp": [3379.06, 3379.72], "text": " I learned a lot."}, {"speaker": "SPEAKER_03", "timestamp": [3381.28, 3383.06], "text": " Thank you to everyone for joining us."}, {"speaker": "SPEAKER_03", "timestamp": [3383.26, 3387.76], "text": " The webinar recording and the slides will be online data today."}, {"speaker": "SPEAKER_03", "timestamp": [3387.76, 3392.2], "text": " We look forward to seeing you all at a future CNCF webinar."}, {"speaker": "SPEAKER_03", "timestamp": [3392.2, 3393.86], "text": " Stay safe and have a great day."}], "chunks": [{"timestamp": [0.0, 2.0], "text": " Sanjeev Rampal, C-NCF Ambassador, Cisco,"}, {"timestamp": [2.0, 4.0], "text": " and C-NCF Ambassador,"}, {"timestamp": [4.0, 6.0], "text": " are here to talk about storage for Kubernetes."}, {"timestamp": [6.0, 8.0], "text": " Sanjeev Rampal, C-NCF Ambassador, Cisco,"}, {"timestamp": [8.0, 10.0], "text": " and C-NCF Ambassador,"}, {"timestamp": [10.0, 12.0], "text": " are here to talk about storage for Kubernetes."}, {"timestamp": [12.0, 14.0], "text": " Sanjeev Rampal, C-NCF Ambassador,"}, {"timestamp": [14.0, 16.0], "text": " and C-NCF Ambassador,"}, {"timestamp": [16.0, 18.0], "text": " are here to talk about storage for Kubernetes."}, {"timestamp": [18.0, 20.0], "text": " Welcome to today's C-NCF webinar."}, {"timestamp": [20.0, 22.0], "text": " Everything you need to know about storage for Kubernetes."}, {"timestamp": [22.0, 24.0], "text": " Everything you need to know about storage for Kubernetes."}, {"timestamp": [24.0, 25.68], "text": " My name is Sanjeev Rampal."}, {"timestamp": [25.68, 29.82], "text": " I'm a principal engineer at Cisco and a CNCF ambassador."}, {"timestamp": [29.82, 32.12], "text": " I'll be moderating today's webinar."}, {"timestamp": [32.12, 36.0], "text": " We would like to welcome our presenter today, Alex Chirkop,"}, {"timestamp": [36.0, 39.66], "text": " founder and CEO at StorageOS."}, {"timestamp": [39.66, 43.0], "text": " Before we get started, a few housekeeping items."}, {"timestamp": [43.0, 45.78], "text": " During the webinar, you will not be able to talk as an"}, {"timestamp": [45.78, 52.0], "text": " attendee. There is a Q&A box at the bottom of your screen. Please feel free to drop your questions in"}, {"timestamp": [52.0, 59.26], "text": " there. And we'll get to as many as we can through the call and at the end. Note the Q&A box is"}, {"timestamp": [59.26, 67.84], "text": " different from the chat box. Please use the Q&A box. This is an official webinar of the CNCF and as such is"}, {"timestamp": [67.84, 73.9], "text": " subject to the CNCF Code of Conduct. Please do not add anything to the chat or questions that"}, {"timestamp": [73.9, 79.3], "text": " would be in violation of that Code of Conduct. Basically, please be respectful of your fellow"}, {"timestamp": [79.3, 87.96], "text": " participants and presenters. With that, I'm going to hand it over to Alex to kick off today's presentation."}, {"timestamp": [88.4, 89.16], "text": " Please go ahead, Alex."}, {"timestamp": [90.68, 94.56], "text": " So good morning, good afternoon, or good evening, wherever you are."}, {"timestamp": [95.42, 98.96], "text": " Hope you're all staying safe and are all well."}, {"timestamp": [99.88, 103.88], "text": " So just a little bit of introduction about myself."}, {"timestamp": [104.32, 113.68], "text": " I'm one of the founders and the CEO of StorageOS, where we've been focusing on building a software-defined"}, {"timestamp": [113.68, 115.46], "text": " cloud-native storage platform."}, {"timestamp": [115.74, 120.06], "text": " And we'll talk a little bit about what a cloud-native storage platform means."}, {"timestamp": [144.86, 147.28], "text": " I'm also the co-chair of the CNCF storage SIG and in the storage SIG we've been working on providing facilities like educational content, like landscape documents, as well as working with the TOC on some of the items, on some of the project reviews for projects that are looking"}, {"timestamp": [147.28, 151.48], "text": " to join the CNCF or to graduate through the CNCF process."}, {"timestamp": [152.54, 159.42], "text": " Before embarking on this startup adventure, I've spent 25 years in infrastructure engineering,"}, {"timestamp": [159.66, 164.86], "text": " you know, trying to build some of the larger infrastructure environments."}, {"timestamp": [165.0, 166.74], "text": " to build some of the larger infrastructure environments."}, {"timestamp": [171.6, 173.7], "text": " I'm gonna get a little plugin for the CNCF SIG storage."}, {"timestamp": [178.7, 178.94], "text": " All the calls are fully open and we meet twice a month."}, {"timestamp": [181.66, 183.5], "text": " Sometimes it's to cover project reviews and project presentations from the community"}, {"timestamp": [183.5, 185.04], "text": " and sometimes it's to work"}, {"timestamp": [185.04, 193.04], "text": " together on different contents that we share through the SIG repo. It would be really great"}, {"timestamp": [193.04, 201.76], "text": " to see some more members attend so feel free to sign up and we'd love to talk to you about"}, {"timestamp": [203.2, 205.76], "text": " the projects that we're working on in the CNCF."}, {"timestamp": [208.42, 215.34], "text": " What I'm going to do in terms of agenda today is I'm going to talk a little bit about some of the"}, {"timestamp": [215.34, 227.08], "text": " challenges of storage in cloud-native environments and discuss some of the principles of what to look for in cloud-native storage environments."}, {"timestamp": [227.9, 234.1], "text": " I'm then going to cover some of the aspects of the storage landscape, which are covered"}, {"timestamp": [234.1, 240.0], "text": " from the CNCF landscape white paper document that we've created."}, {"timestamp": [240.82, 254.68], "text": " And I'm also going to talk about some of the internals of how Kubernetes uses APIs like CSI to work with different storage providers to manage storage within their environment."}, {"timestamp": [269.28, 275.96], "text": " Godz was heard, we'll move ahead and have a little demo where I can show the use of some of the Kubernetes technologies like storage classes and PVCs and PVs to run a stateful"}, {"timestamp": [275.96, 283.08], "text": " workload like a database in Kubernetes."}, {"timestamp": [283.08, 287.3], "text": " So first off, we want to discuss why is storage important."}, {"timestamp": [287.7, 290.2], "text": " So I'm going to say something fairly controversial here."}, {"timestamp": [291.82, 294.98], "text": " Despite everything about containers being stateless,"}, {"timestamp": [295.58, 298.34], "text": " there is no such thing as a stateless architecture, right?"}, {"timestamp": [298.34, 302.06], "text": " All applications are looking to store state somewhere,"}, {"timestamp": [302.78, 306.44], "text": " whether it is consuming, whether those applications are"}, {"timestamp": [306.44, 312.0], "text": " consuming services that exist outside of the Kubernetes cluster, or whether they're using"}, {"timestamp": [312.0, 318.62], "text": " services or storage functionality that lives within the Kubernetes cluster. Now,"}, {"timestamp": [319.72, 328.44], "text": " cloud native storage is a very different beast. When we talk about Kubernetes, we're very familiar with"}, {"timestamp": [328.44, 337.72], "text": " the concept of pets versus cattle, right? So the concept that nodes are specially curated and have"}, {"timestamp": [337.72, 345.04], "text": " special resources or special services is a complete anti-pattern to the way Kubernetes clusters are deployed."}, {"timestamp": [345.86, 349.36], "text": " What we really want is we want an environment"}, {"timestamp": [349.36, 353.92], "text": " where your Kubernetes cluster is treated like cattle."}, {"timestamp": [353.92, 362.54], "text": " So every node is homogeneous and can be used to deploy applications."}, {"timestamp": [362.88, 363.9], "text": " and can be used to deploy applications."}, {"timestamp": [367.94, 368.9], "text": " Now, in much the same way that today,"}, {"timestamp": [371.82, 374.5], "text": " a developer can use a bit of YAML to specify, hey, this is my application, this is what it looks like,"}, {"timestamp": [374.5, 377.22], "text": " it needs this amount of CPU, this amount of memory,"}, {"timestamp": [378.42, 381.18], "text": " and maybe some network connectivity."}, {"timestamp": [383.14, 389.74], "text": " Kubernetes then goes away and takes that declaration or that piece of YAML"}, {"timestamp": [389.74, 395.34], "text": " and kind of does a really good job at playing Tetris with your infrastructure."}, {"timestamp": [395.6, 400.48], "text": " So it abstracts away all of the services that are available in the infrastructure and does"}, {"timestamp": [400.48, 406.64], "text": " the best to fit the applications in the most efficient way to that deployment"}, {"timestamp": [407.92, 415.6], "text": " and makes sure that we maintain rules to maintain scalability or health."}, {"timestamp": [416.16, 423.2], "text": " So based on the fact that applications within Kubernetes use this sort of functionality,"}, {"timestamp": [427.54, 434.2], "text": " Kubernetes use this sort of functionality. You should also look for a cloud native storage solution where the solution is both declarative and composable, right? And in order to do this,"}, {"timestamp": [434.64, 442.76], "text": " you're looking for a storage system that has a rich API-driven process that Kubernetes can"}, {"timestamp": [442.76, 447.52], "text": " interact with. So in much the same way that you specify CPU, memory,"}, {"timestamp": [447.52, 452.32], "text": " and network requirements, you should also be able to specify something like, you know, I need"}, {"timestamp": [452.32, 457.92], "text": " 100 gigabytes and it needs to have these sorts of storage attributes like replication or encryption"}, {"timestamp": [457.92, 470.44], "text": " applied. The second challenge we see with cloudative storage is that data needs to be able to follow applications, right?"}, {"timestamp": [470.56, 484.86], "text": " So in a traditional storage architecture, you're very often presenting volumes or consuming storage on specific servers or nodes or VMs."}, {"timestamp": [489.72, 494.96], "text": " storage on specific servers or nodes or VMs. And in cloud-native storage, we have a major difference here. The storage isn't being consumed by the node, but rather it's being consumed by"}, {"timestamp": [494.96, 499.86], "text": " the application that's running on the node. And a lot of effort obviously has gone into"}, {"timestamp": [499.86, 506.78], "text": " containerizing the application and making the application portable. So this application can now run on any nodes in the cluster."}, {"timestamp": [507.68, 512.6], "text": " So you need to make sure that the storage subsystem can also apply the same"}, {"timestamp": [512.6, 518.08], "text": " rules and effectively be able to follow the application wherever it moves"}, {"timestamp": [518.08, 521.02], "text": " within the data center or within the cluster."}, {"timestamp": [522.6, 524.2], "text": " The other thing is, obviously,"}, {"timestamp": [524.74, 527.2], "text": " since Kubernetes does such a great job"}, {"timestamp": [527.2, 529.48], "text": " at abstracting away the infrastructure,"}, {"timestamp": [529.82, 534.26], "text": " allowing you to effectively deploy an application"}, {"timestamp": [534.26, 535.28], "text": " in much the same way,"}, {"timestamp": [535.36, 538.22], "text": " whether you're running bare metal on-prem"}, {"timestamp": [538.22, 541.84], "text": " or in VMs or in cloud instances,"}, {"timestamp": [542.2, 543.88], "text": " you're also looking for a storage system"}, {"timestamp": [543.88, 545.1], "text": " that can be platform agnostic"}, {"timestamp": [545.1, 551.62], "text": " and work across all of those different platforms too. And finally, and I know this is a little"}, {"timestamp": [551.62, 557.22], "text": " cliched, but I'll go as far as saying, you know, you want to look at the agility of the storage"}, {"timestamp": [557.22, 562.68], "text": " system too. So it's one of the things that needs to be considered because Kubernetes environments"}, {"timestamp": [562.68, 565.22], "text": " tends to be more dynamic."}, {"timestamp": [567.7, 569.28], "text": " They are designed to be dynamically scaled and dynamically upgraded,"}, {"timestamp": [569.56, 571.06], "text": " and therefore nodes come and go"}, {"timestamp": [571.06, 573.84], "text": " and nodes are scaled up and scaled down."}, {"timestamp": [574.52, 576.88], "text": " So you want a storage system that can adapt"}, {"timestamp": [576.88, 580.1], "text": " to the changing nature of the Kubernetes environment."}, {"timestamp": [582.26, 585.16], "text": " And then finally, this is kind of obvious, right?"}, {"timestamp": [585.16, 592.06], "text": " The people are deploying the automation and using Kubernetes to automate everything with"}, {"timestamp": [592.06, 593.62], "text": " their infrastructure, right?"}, {"timestamp": [593.62, 598.24], "text": " And make it predictable and recreateable."}, {"timestamp": [598.24, 604.22], "text": " So this kind of feeds on the concept of cattle versus pets too."}, {"timestamp": [604.22, 606.88], "text": " That said, because we're looking to automate everything"}, {"timestamp": [606.88, 608.44], "text": " within the infrastructure,"}, {"timestamp": [608.84, 612.3], "text": " we also want to make sure that the automation applies"}, {"timestamp": [612.3, 613.6], "text": " to the storage environment"}, {"timestamp": [613.6, 616.58], "text": " and that the storage environment is consistently available"}, {"timestamp": [616.58, 620.34], "text": " and sort of protects the data within your Kubernetes cluster"}, {"timestamp": [620.34, 623.84], "text": " and can also provide the appropriate levels"}, {"timestamp": [623.84, 626.52], "text": " of performance and security that interact"}, {"timestamp": [626.52, 628.48], "text": " with the Kubernetes environment."}, {"timestamp": [628.48, 637.5], "text": " So predictable, deterministic performance and security that natively works with Kubernetes"}, {"timestamp": [637.5, 644.82], "text": " access controls and Kubernetes namespaces, for example, are strong attributes that you"}, {"timestamp": [644.82, 645.76], "text": " should be looking out for."}, {"timestamp": [649.04, 656.96], "text": " So I'm going to move into talking next about the CNCF storage landscape white paper."}, {"timestamp": [659.6, 669.72], "text": " The storage landscape white paper is a document that we started working on now probably about 18, 24 months back."}, {"timestamp": [670.46, 675.54], "text": " And we've had contributions and lots of reviews on the document."}, {"timestamp": [676.48, 688.5], "text": " And what we've tried to do here is we've tried to explain the different components and different attributes of a storage system, covering where a storage"}, {"timestamp": [688.5, 694.12], "text": " system can be deployed, the various attributes of the storage system, the layers and the topology"}, {"timestamp": [694.12, 700.78], "text": " within a storage system, as well as how you access storage and the management interfaces"}, {"timestamp": [700.78, 709.84], "text": " that are used on the control plane for those storage systems. So the reason why this is important is because storage is a very broad topic,"}, {"timestamp": [709.84, 716.8], "text": " right? So we tend to think of storage traditionally as volumes,"}, {"timestamp": [716.8, 723.24], "text": " but in a cloud-native world, storage is any way you can persist data. So in"}, {"timestamp": [723.24, 729.14], "text": " the cloud-native world, you kind of have two types of methods of doing that."}, {"timestamp": [729.28, 735.46], "text": " One is with traditional volumes and one is sort of API based methods, which includes things like"}, {"timestamp": [735.46, 742.24], "text": " object stores and databases and key value stores, for example. And more than ever before, it's"}, {"timestamp": [742.24, 750.5], "text": " becoming really important for developers to understand the storage attributes of their system and to understand how the storage system works."}, {"timestamp": [750.5, 759.54], "text": " Because they need to ensure that those attributes match to what their application requires."}, {"timestamp": [760.22, 762.62], "text": " So we'll talk a little bit about the attributes in a second."}, {"timestamp": [762.62, 763.54], "text": " So we'll talk a little bit about the attributes in a second."}, {"timestamp": [770.42, 771.62], "text": " The first point is there are lots of different ways of deploying storage within an environment, right?"}, {"timestamp": [778.5, 778.98], "text": " The more traditional hardware solutions are typically deployed in a data center."}, {"timestamp": [787.9, 795.2], "text": " But obviously, some of those solutions have limitations on the portability and the use of those solutions within cloud environments. Software solutions tend to be more platform agnostic, and some"}, {"timestamp": [795.2, 801.36], "text": " software solutions and some of the projects that we're looking at in both commercial vendors"}, {"timestamp": [801.36, 806.66], "text": " and CNCF projects, you have software solutions that can be"}, {"timestamp": [806.66, 811.46], "text": " deployed as a container and the deployment can actually be automated"}, {"timestamp": [811.46, 817.38], "text": " through an orchestrator too. And finally of course there are storage services"}, {"timestamp": [817.38, 826.42], "text": " which can be consumed from the public cloud providers. So public cloud providers provide services like object stores or disk"}, {"timestamp": [826.42, 836.16], "text": " volumes too. So we talked a little bit about the storage attributes, but why is it important"}, {"timestamp": [836.16, 847.64], "text": " to understand what these different storage attributes mean? So when we drew up the landscape white paper, we classified the attributes into five different"}, {"timestamp": [847.64, 849.18], "text": " main types."}, {"timestamp": [849.18, 856.4], "text": " Availability, scalability, performance, consistency, and durability."}, {"timestamp": [856.4, 861.0], "text": " What we found was, as we were discussing these different attributes, is that each of these"}, {"timestamp": [861.0, 865.92], "text": " attributes are important to different aspects of an application. So for example,"}, {"timestamp": [867.12, 873.68], "text": " most applications have architecture patterns that depend on a storage subsystem to provide"}, {"timestamp": [873.68, 878.72], "text": " a layer of availability. So if an application needs to move between nodes or failover,"}, {"timestamp": [879.36, 883.6], "text": " it needs to be able to continue to access the same data, for example."}, {"timestamp": [883.62, 892.12], "text": " be able to continue to access the same data, for example. Similarly, another lever or another aspect that is very important for some applications"}, {"timestamp": [892.12, 893.88], "text": " is scalability."}, {"timestamp": [893.88, 898.72], "text": " Now, scalability, again, can be measured in a number of different ways."}, {"timestamp": [898.72, 904.12], "text": " It could be the scalability of the number of operations or the throughput of that environment,"}, {"timestamp": [904.12, 910.18], "text": " or it could be things like the scalability of the number of concurrent clients, for example, that can connect"}, {"timestamp": [910.18, 916.26], "text": " into the system, or indeed the number of components. So does the system scale horizontally"}, {"timestamp": [916.26, 922.78], "text": " or does it scale vertically, for example? Similarly, we talked about deterministic"}, {"timestamp": [922.78, 929.22], "text": " performance, and often performance is one of the key measures of a storage system that people want to understand."}, {"timestamp": [930.22, 945.0], "text": " But again, most storage system topologies have a number of compromises, and they are typically optimized for some combination of different performance parameters."}, {"timestamp": [945.72, 951.54], "text": " So what we see is we see some storage systems, for example, that are highly optimized for"}, {"timestamp": [951.54, 959.14], "text": " low latency and are suitable, for example, for transactional systems, which require that"}, {"timestamp": [959.14, 966.44], "text": " low latency per operation, whereas other storage systems are optimized for throughput, for example,"}, {"timestamp": [967.0, 971.76], "text": " for things like data analytics or data warehousing type operations."}, {"timestamp": [974.16, 978.92], "text": " When we talk about compromises and optimizations of the different storage systems, the other"}, {"timestamp": [978.92, 991.58], "text": " aspect to keep in mind is the consistency. So most systems will have some level of, you know,"}, {"timestamp": [991.64, 994.1], "text": " different levers on the consistency attributes"}, {"timestamp": [994.1, 998.24], "text": " that dramatically affect availability, scalability, and performance."}, {"timestamp": [998.88, 1000.82], "text": " And consistency is measured in two vectors."}, {"timestamp": [1000.82, 1009.84], "text": " One is the amount of time that it takes to commit the data to non-volatile storage"}, {"timestamp": [1010.64, 1016.96], "text": " once it's been committed. And the second is the delay once that data has been committed to be"}, {"timestamp": [1016.96, 1022.16], "text": " able to access that consistently across all the different nodes in a cluster, right? And you'll"}, {"timestamp": [1022.16, 1026.96], "text": " find that some applications can tolerate eventual consistency"}, {"timestamp": [1026.96, 1031.94], "text": " and some applications need very strong synchronous consistency."}, {"timestamp": [1033.52, 1037.08], "text": " And then finally, we look at durability, right?"}, {"timestamp": [1037.08, 1042.68], "text": " And durability sometimes gets confused with availability,"}, {"timestamp": [1043.52, 1047.04], "text": " but they are fundamentally different things. So availability"}, {"timestamp": [1047.04, 1052.56], "text": " is talking about the ability of storage to fail over and to move between nodes and to provide"}, {"timestamp": [1052.56, 1061.12], "text": " some level of redundancy. The durability is a measure of the way that the data is protected"}, {"timestamp": [1061.12, 1068.08], "text": " on the back end in the system, and that includes redundancy. But it also includes"}, {"timestamp": [1068.08, 1071.04], "text": " additional measures like, for example, the way the storage system"}, {"timestamp": [1071.68, 1075.68], "text": " protects against corruption on the underlying disk media, for example."}, {"timestamp": [1079.04, 1097.56], "text": " So we move on then to the storage layers within a storage system. So in a storage system, it's now more common than ever that a typical environment will be composed of a number of different layers."}, {"timestamp": [1098.32, 1103.68], "text": " And some of the layers can be intermingled from different systems."}, {"timestamp": [1103.68, 1104.24], "text": " can be intermingled from different systems."}, {"timestamp": [1109.38, 1109.46], "text": " So it's not uncommon to find different storage systems,"}, {"timestamp": [1111.18, 1113.7], "text": " for example, layers on top of each other to provide different services or different functionality."}, {"timestamp": [1114.8, 1120.82], "text": " At the very top, you have the work that the orchestrator is doing,"}, {"timestamp": [1121.3, 1124.04], "text": " things like virtualizing the mount points"}, {"timestamp": [1124.04, 1125.28], "text": " and making sure that mount points"}, {"timestamp": [1126.08, 1133.76], "text": " are available on different nodes within a cluster and the integration into things like"}, {"timestamp": [1133.76, 1143.84], "text": " namespaces and the container bind lines for example. Another factor to consider within"}, {"timestamp": [1145.38, 1148.36], "text": " to consider within the storage layers is the topology that the storage systems use."}, {"timestamp": [1149.44, 1151.22], "text": " There are storage systems"}, {"timestamp": [1151.22, 1154.0], "text": " that have a very centralized topology,"}, {"timestamp": [1154.44, 1156.54], "text": " perhaps because they have"}, {"timestamp": [1156.54, 1159.22], "text": " some proprietary hardware interconnects"}, {"timestamp": [1159.22, 1162.52], "text": " or they're designed for scaling vertically."}, {"timestamp": [1163.86, 1167.04], "text": " And those sort of systems tend to be optimized"}, {"timestamp": [1167.04, 1169.54], "text": " for performance and low latency,"}, {"timestamp": [1169.7, 1171.32], "text": " but obviously they have the complexity"}, {"timestamp": [1171.32, 1175.42], "text": " of only being able to scale vertically."}, {"timestamp": [1175.98, 1179.36], "text": " You then move into distributed systems,"}, {"timestamp": [1179.36, 1184.36], "text": " which tends to provide much better scaling capabilities"}, {"timestamp": [1184.92, 1189.2], "text": " by scaling horizontally rather than vertically."}, {"timestamp": [1189.98, 1197.6], "text": " But distributed systems then have additional complexity and additional latency requirements"}, {"timestamp": [1197.6, 1203.26], "text": " that need to be taken into consideration because the data is spread out across more nodes"}, {"timestamp": [1203.26, 1206.9], "text": " and therefore across more network connectivity is important."}, {"timestamp": [1208.02, 1214.18], "text": " And then there are also technologies which often apply to databases called sharding, for example,"}, {"timestamp": [1214.58, 1224.4], "text": " where scaling and distribution of data is done by filtering the data into different buckets"}, {"timestamp": [1224.4, 1227.12], "text": " and placing different buckets on different"}, {"timestamp": [1227.12, 1228.12], "text": " systems."}, {"timestamp": [1228.12, 1233.2], "text": " And the last topology I'd like to talk about is hyperconverged, which is something that's"}, {"timestamp": [1233.2, 1236.78], "text": " becoming a bit more common nowadays."}, {"timestamp": [1236.78, 1249.04], "text": " And what we're talking about here is an environment where nodes are simultaneously providing storage to a storage subsystem and used to provide"}, {"timestamp": [1250.8, 1256.48], "text": " storage capacity whilst also running applications and compute capabilities."}, {"timestamp": [1258.16, 1263.12], "text": " The next layer down talks about the way the data is protected within those systems."}, {"timestamp": [1264.12, 1266.96], "text": " at the way the data is protected within those systems. We have things like traditional systems"}, {"timestamp": [1266.96, 1270.72], "text": " that might use some form of RAID,"}, {"timestamp": [1270.72, 1275.36], "text": " which effectively creates parity or mirrors for the data."}, {"timestamp": [1275.36, 1277.24], "text": " More commonly in distributed systems,"}, {"timestamp": [1277.24, 1279.08], "text": " we see erasure coding,"}, {"timestamp": [1279.08, 1281.56], "text": " which again is a way of creating,"}, {"timestamp": [1281.56, 1284.16], "text": " of splitting the data into multiple components"}, {"timestamp": [1284.16, 1285.86], "text": " and creating multiple"}, {"timestamp": [1285.86, 1295.84], "text": " fragments of parity and data that can be used to recover the data if any individual nodes"}, {"timestamp": [1295.84, 1296.42], "text": " goes down."}, {"timestamp": [1297.6, 1303.48], "text": " And then we have the concept of replicas, which where data is replicated in its entirety"}, {"timestamp": [1303.48, 1305.26], "text": " to a number of different nodes."}, {"timestamp": [1306.6, 1316.12], "text": " And often this is a big sort of play between performance, data protection, and availability and durability."}, {"timestamp": [1316.12, 1322.78], "text": " So things like erasure coding provides amazing durability, but typically at a latency cost."}, {"timestamp": [1322.78, 1323.7], "text": " but typically at a latency cost."}, {"timestamp": [1329.2, 1329.44], "text": " And things like replicas provide a lower latency solution,"}, {"timestamp": [1332.3, 1333.32], "text": " but typically at the cost of using additional capacity."}, {"timestamp": [1336.98, 1341.0], "text": " Now, one thing that mustn't be forgotten is the concept that every storage system also provides some layer of data services."}, {"timestamp": [1341.3, 1344.82], "text": " So things like replication of data or snapshots or clones,"}, {"timestamp": [1346.0, 1352.74], "text": " which are point-in-time copies of data services. So things like replication of data or snapshots or clones, which are point in time copies of data, which are typically important for different workflows, whether it's, you know,"}, {"timestamp": [1352.78, 1358.88], "text": " providing disaster recovery or business continuity, or providing backup functionality"}, {"timestamp": [1358.88, 1366.16], "text": " in your system. And we can't forget the physical or the non-volatile layer, right? So,"}, {"timestamp": [1367.76, 1376.24], "text": " you know, from traditional spinning media to fast solid-state devices and moving forward to"}, {"timestamp": [1376.24, 1381.44], "text": " non-volatile, you know, memory class type components, each of those components offer"}, {"timestamp": [1382.16, 1387.2], "text": " a variety of different storage attributes when it comes to,"}, {"timestamp": [1387.2, 1391.2], "text": " you know, obviously performance, but also more importantly things like durability too."}, {"timestamp": [1394.88, 1403.44], "text": " One of the things that's quite interesting is we try to put a table in place to"}, {"timestamp": [1404.4, 1408.64], "text": " compare the different storage topologies between local, remote, and"}, {"timestamp": [1408.64, 1416.8], "text": " distributed systems. And we kind of see that the topology comparison affects each of those storage"}, {"timestamp": [1416.8, 1425.2], "text": " attributes by quite an amount, right? So local systems, for example, are limited in availability,"}, {"timestamp": [1425.2, 1429.36], "text": " whereas remote and distributed systems have better availability and better scalability."}, {"timestamp": [1430.88, 1439.76], "text": " But of course, performance tends to be lower in local systems. And we'll talk a little bit about"}, {"timestamp": [1439.76, 1446.12], "text": " state of locality in a minute. But obviously remote and distributed systems tend to have slightly higher latencies."}, {"timestamp": [1449.22, 1453.22], "text": " So we move on then to the data access interfaces."}, {"timestamp": [1453.22, 1456.46], "text": " And we talked a little bit earlier on"}, {"timestamp": [1456.46, 1460.88], "text": " about the concept of volumes and APIs, right?"}, {"timestamp": [1461.26, 1464.22], "text": " So it's really important to distinguish"}, {"timestamp": [1464.94, 1467.28], "text": " between the data access interface,"}, {"timestamp": [1467.44, 1474.74], "text": " which is what a container or an application uses to actually access the data, and the control"}, {"timestamp": [1474.74, 1489.38], "text": " plane that the orchestrator uses to do things like dynamic provisioning of volumes or management of the storage system. So it's probably fair to say that the most mature APIs"}, {"timestamp": [1490.44, 1493.38], "text": " that are available today with Kubernetes integration"}, {"timestamp": [1493.38, 1494.86], "text": " are volumes."}, {"timestamp": [1494.86, 1497.2], "text": " So things like block devices, file systems"}, {"timestamp": [1497.2, 1498.84], "text": " and shared file systems."}, {"timestamp": [1500.52, 1510.72], "text": " And a lot of databases or message queues or instrumentation like Prometheus, for example, will depend on being able to use these sorts of volumes."}, {"timestamp": [1511.56, 1526.72], "text": " But likewise, of course, there are a whole suite of storage systems that provide object store interfaces or key value stores or databases that are accessed over an API. And those sorts of systems, for example,"}, {"timestamp": [1529.2, 1532.56], "text": " will typically be using that API over a network."}, {"timestamp": [1538.0, 1551.36], "text": " Each of the different data access interfaces are typically suited to different sets of attributes. So what I'm going to do,"}, {"timestamp": [1552.0, 1557.6], "text": " what I'm going to let that settle in for a second and you can see some of the comparisons on the"}, {"timestamp": [1557.6, 1573.2], "text": " screen. So for example, you know, you typically expect block systems to perhaps have a lower latency or file systems to be able to provide the ability to share workloads across multiple nodes, for example."}, {"timestamp": [1573.2, 1579.56], "text": " And object stores are well known for being able to scale to very large capacities, for example."}, {"timestamp": [1589.96, 1590.8], "text": " But that said, one word of caution that caveats all of this is that, you know, we go back to the storage topologies and the layering."}, {"timestamp": [1595.88, 1609.44], "text": " We often have to try and understand what is happening within a storage system, right? So sometimes if you have block devices, which are typically, you know, linked to, for example, a physical low latency device in the server."}, {"timestamp": [1610.56, 1616.56], "text": " Block systems can now, block devices can now work remotely and can work on distributed storage"}, {"timestamp": [1616.56, 1626.4], "text": " systems and therefore they inherit the storage attributes of that distributed system. Similarly, for example, there are"}, {"timestamp": [1626.4, 1632.46], "text": " many file systems that are built on an object store backend and therefore they"}, {"timestamp": [1632.46, 1637.32], "text": " have the, you know, they inherit the latency and the availability and"}, {"timestamp": [1637.32, 1641.54], "text": " durability of the object store rather than just the"}, {"timestamp": [1641.54, 1646.6], "text": " attributes of the file system. So understanding the layering is fairly important"}, {"timestamp": [1646.6, 1649.04], "text": " when we're trying to look at these comparisons."}, {"timestamp": [1651.62, 1655.46], "text": " And then we move on to the orchestration and management interfaces."}, {"timestamp": [1655.82, 1658.86], "text": " So this is how things like dynamic provisioning work"}, {"timestamp": [1658.86, 1661.4], "text": " between Kubernetes and the storage system."}, {"timestamp": [1661.4, 1667.02], "text": " So the container orchestrator of Kubernetes has a control plane interface."}, {"timestamp": [1667.28, 1669.02], "text": " There are a number of these interfaces"}, {"timestamp": [1669.02, 1672.96], "text": " and they talk to the control plane in the storage system."}, {"timestamp": [1673.26, 1675.12], "text": " Now, in some cases,"}, {"timestamp": [1675.12, 1681.42], "text": " the storage system supports the control plane APIs natively."}, {"timestamp": [1682.5, 1683.48], "text": " And in some cases,"}, {"timestamp": [1684.3, 1689.84], "text": " the orchestrator is talking via a framework or a set of tools"}, {"timestamp": [1690.4, 1696.96], "text": " to provide the bridge between the orchestrator API and the storage system API."}, {"timestamp": [1698.0, 1709.4], "text": " Of course, as we discussed before, the workloads talk to the data plane via the data access interface, which is very separate from the control plane interfaces."}, {"timestamp": [1710.18, 1715.56], "text": " So you might ask, OK, we've listed a number of different control plane interfaces, but what do they all mean?"}, {"timestamp": [1716.28, 1720.54], "text": " So the key interface here is the container storage interface."}, {"timestamp": [1721.36, 1728.28], "text": " The container storage interface is similar to CNI for networking or CRI for"}, {"timestamp": [1728.28, 1737.52], "text": " the runtime. It is a standard API which was adopted between orchestrators like Kubernetes"}, {"timestamp": [1737.52, 1748.28], "text": " and different storage vendors. So currently there are, I actually lost track, but there's easily 50 or more storage systems"}, {"timestamp": [1748.28, 1750.08], "text": " that support the CSI interface"}, {"timestamp": [1750.08, 1752.94], "text": " that integrate with Kubernetes."}, {"timestamp": [1754.38, 1760.64], "text": " I'm highlighting CSI because this is the factor standard"}, {"timestamp": [1760.64, 1766.8], "text": " for interfacing Kubernetes to different storage systems and different storage services."}, {"timestamp": [1767.52, 1773.08], "text": " In the past, we had drivers that were mainlined into the Kubernetes source,"}, {"timestamp": [1773.7, 1787.64], "text": " and we had the concept of Kubernetes flex volumes. But if you're trying to implement a new system nowadays, it's probably worth focusing entirely on CSI"}, {"timestamp": [1787.64, 1790.84], "text": " because that's the standard where all the development"}, {"timestamp": [1790.84, 1794.14], "text": " and advancements are happening today."}, {"timestamp": [1798.6, 1800.72], "text": " So we'll talk a little bit now"}, {"timestamp": [1800.72, 1804.2], "text": " about how storage is configured in Kubernetes."}, {"timestamp": [1804.74, 1806.08], "text": " So now that we talked about and"}, {"timestamp": [1806.08, 1811.28], "text": " we kind of set the scene of the storage system with all these different layers and different"}, {"timestamp": [1811.28, 1817.36], "text": " data access methods and different control plane access methods, what does this actually translate"}, {"timestamp": [1817.36, 1826.18], "text": " to in real life and how do these systems interact with Kubernetes?"}, {"timestamp": [1832.12, 1837.5], "text": " So we'll talk a little bit first about the concept of dynamic provisioning. So you remember when we said storage needs to be application-centric,"}, {"timestamp": [1838.26, 1845.4], "text": " and therefore that enables self-service and declarative and composable storage."}, {"timestamp": [1846.16, 1849.08], "text": " How is this actually achieved?"}, {"timestamp": [1849.08, 1855.62], "text": " So the main abstraction layer here is called a storage class."}, {"timestamp": [1856.5, 1865.0], "text": " So effectively, a storage class is a definition that specifies a driver interface,"}, {"timestamp": [1866.36, 1868.58], "text": " typically through CSI,"}, {"timestamp": [1868.58, 1873.58], "text": " that driver interface will be used by the storage system"}, {"timestamp": [1874.5, 1876.9], "text": " to provide and manage the storage, right?"}, {"timestamp": [1876.9, 1880.88], "text": " And this is in relation to dynamically provisioning"}, {"timestamp": [1880.88, 1884.62], "text": " the storage, but also things like attaching storage"}, {"timestamp": [1884.62, 1886.62], "text": " to physical nodes or"}, {"timestamp": [1886.62, 1892.6], "text": " to nodes within the cluster and mounting that storage and managing the storage lifecycle."}, {"timestamp": [1892.6, 1898.0], "text": " So that's all well and good, but what does a storage class really look like? So a storage"}, {"timestamp": [1898.0, 1909.04], "text": " class is actually typically something really, really simple like this. The storage class defines a name. So in this case, we're"}, {"timestamp": [1909.04, 1915.12], "text": " calling it fast because you can create different storage classes for different types of environments."}, {"timestamp": [1916.18, 1924.48], "text": " It might specify some labels or flags that are specific to the storage system. And it"}, {"timestamp": [1924.48, 1926.08], "text": " defines the provisioner."}, {"timestamp": [1926.14, 1929.82], "text": " In this case, we've simplified it and just called it storageOS."}, {"timestamp": [1930.0, 1935.04], "text": " But if we were using CSI, the provisioner would be a CSI provisioner."}, {"timestamp": [1936.78, 1943.6], "text": " What this translates to then is how do developers who want to use"}, {"timestamp": [1943.6, 1949.84], "text": " that composable storage, how do they actually register what they need?"}, {"timestamp": [1949.84, 1956.3], "text": " So the constant here is a persistent volume claim."}, {"timestamp": [1956.3, 1963.04], "text": " So within the definition of your application or your pods,"}, {"timestamp": [1963.04, 1967.68], "text": " you can make a persistent volume claim from the pool of storage"}, {"timestamp": [1967.68, 1975.44], "text": " that's linked to that storage class. Again, what does a persistent volume claim look like?"}, {"timestamp": [1975.44, 1980.4], "text": " Well, fundamentally, it's really, really simple. You give it a name. In this case,"}, {"timestamp": [1980.4, 1986.02], "text": " we're calling it a database volume. You tell it which storage class to use. In this case, we're calling it a database volume. You tell it which storage class to use."}, {"timestamp": [1986.04, 1987.62], "text": " In this case, we're specifying the fast."}, {"timestamp": [1988.8, 1992.28], "text": " And you specify the size of the storage."}, {"timestamp": [1993.34, 1996.6], "text": " I'll talk a little bit about the access modes in a little bit."}, {"timestamp": [1997.8, 2000.32], "text": " But fundamentally, all it is is you say,"}, {"timestamp": [2000.54, 2003.1], "text": " I'm going to give a name to my persistent volume claim."}, {"timestamp": [2003.1, 2011.28], "text": " I'm going to use a particular storage class and it's this amount of capacity. It is also possible to pass things like labels"}, {"timestamp": [2011.28, 2018.0], "text": " which might affect the provisioning capabilities of which might be specific to a particular storage"}, {"timestamp": [2018.0, 2032.2], "text": " system too. What happens then behind the scenes is that Kubernetes talks over the storage interface to the storage system."}, {"timestamp": [2032.8, 2035.64], "text": " The storage system creates a persistent volume."}, {"timestamp": [2036.06, 2043.9], "text": " So we said that the developer makes a claim and the storage system replies by saying, hey, here you are."}, {"timestamp": [2044.3, 2046.16], "text": " This is your persistent volume."}, {"timestamp": [2047.08, 2054.72], "text": " You then reference that claim in the pod. And when your application in the pod is started,"}, {"timestamp": [2055.44, 2064.02], "text": " that persistent volume is connected into the pod. So moving forward a little bit,"}, {"timestamp": [2067.68, 2078.3], "text": " the pods. So moving forward a little bit, what does that actually look like? So this is an example of a simple, you know, an empty pods that just runs a sleep command and uses a PVC1 claim."}, {"timestamp": [2079.04, 2087.84], "text": " So what we see here is when the PVC is requested, the storage system will create the persistent volume like we"}, {"timestamp": [2087.84, 2095.04], "text": " just described, and then that persistent volume is attached to a node and is mounted, typically"}, {"timestamp": [2095.04, 2105.0], "text": " in farlib-kubelet, a long path name in farlib-kubelet. Once that happens and the container is then started,"}, {"timestamp": [2105.0, 2110.0], "text": " that part in the node is bind mounted"}, {"timestamp": [2110.18, 2112.0], "text": " into the specified mount point,"}, {"timestamp": [2112.0, 2114.28], "text": " which in this case is slash MNT"}, {"timestamp": [2114.28, 2116.2], "text": " within the container namespace."}, {"timestamp": [2116.2, 2119.56], "text": " So the application starts and now has access"}, {"timestamp": [2119.56, 2122.8], "text": " to a file system or that volume under,"}, {"timestamp": [2122.8, 2128.24], "text": " in this case, the slash mnt mount point. If that application"}, {"timestamp": [2128.24, 2137.76], "text": " then moves to different nodes within the cluster, the reverse happens. The persistent volume is"}, {"timestamp": [2137.76, 2146.48], "text": " detached and reattached on another node and then remounted and can be reused by an application on the other node."}, {"timestamp": [2150.32, 2156.16], "text": " So if you recall, we talked a little bit about volume access modes too. So in the volume access"}, {"timestamp": [2156.16, 2167.12], "text": " modes, we have two typical modes. One is RedriveOnce and one is Redrive many. So read write once means that the volume is mounted and accessed"}, {"timestamp": [2167.12, 2173.28], "text": " exclusively only by one node. This is this is typically the type of storage that you'd see from"}, {"timestamp": [2173.28, 2182.32], "text": " say block storage services. We also have the read write many and this will typically be used to"}, {"timestamp": [2182.32, 2192.86], "text": " access a shared file system. So so effectively this gives the ability to mount a file system on multiple nodes simultaneously."}, {"timestamp": [2193.74, 2200.34], "text": " And that can be used for different storage patterns, perhaps,"}, {"timestamp": [2200.56, 2207.32], "text": " where a common file system needs to be available to provide a consistent level of config"}, {"timestamp": [2207.32, 2209.08], "text": " or a consistent level of reference data"}, {"timestamp": [2209.08, 2212.08], "text": " to multiple nodes within a system."}, {"timestamp": [2214.06, 2214.9], "text": " Okay."}, {"timestamp": [2218.46, 2221.8], "text": " So what I'm going to do is I'm going to show"}, {"timestamp": [2221.8, 2234.72], "text": " a very, very quick example, assuming everything works, of provisioning a stateful workload and moving a stateful workload from one node to another in a Kubernetes cluster."}, {"timestamp": [2235.54, 2243.42], "text": " For reference, I'm just using one of the simple examples that's available on the StorageOS website."}, {"timestamp": [2244.3, 2247.74], "text": " But obviously, you can run any application"}, {"timestamp": [2247.74, 2250.36], "text": " with any number of different storage systems."}, {"timestamp": [2251.78, 2253.4], "text": " In this particular example,"}, {"timestamp": [2253.64, 2257.66], "text": " I'm going to start up a MySQL database"}, {"timestamp": [2257.66, 2261.42], "text": " and I'm using the free StorageOS developer edition,"}, {"timestamp": [2261.68, 2267.38], "text": " which is free forever and available on our website."}, {"timestamp": [2268.38, 2276.46], "text": " The stateful set definition effectively tells Kubernetes to make a claim for a MySQL database"}, {"timestamp": [2276.46, 2283.62], "text": " and to start it up with Firelib MySQL in the mount part."}, {"timestamp": [2284.28, 2287.08], "text": " So I've already done this."}, {"timestamp": [2287.82, 2296.0], "text": " So what I'm going to do now is I will briefly unshare my screen"}, {"timestamp": [2296.0, 2313.08], "text": " and I will now share my demo."}, {"timestamp": [2318.18, 2319.18], "text": " Sanjeev, can you just confirm that the demo screen is loaded?"}, {"timestamp": [2320.28, 2320.44], "text": " Yes, Alex."}, {"timestamp": [2320.9, 2321.48], "text": " Looks good."}, {"timestamp": [2321.82, 2322.14], "text": " Awesome."}, {"timestamp": [2322.42, 2323.44], "text": " All right."}, {"timestamp": [2328.9, 2330.24], "text": " So I'm going to be using a little tool called K9S"}, {"timestamp": [2333.54, 2337.32], "text": " to provide visibility of what's going on in the cluster. K9S is an open source tool,"}, {"timestamp": [2337.32, 2340.02], "text": " but it's really great at visualizing what's going on"}, {"timestamp": [2340.02, 2341.24], "text": " in the Kubernetes cluster."}, {"timestamp": [2341.24, 2342.56], "text": " One quick one, Alex,"}, {"timestamp": [2342.56, 2345.76], "text": " if you could maybe magnify the font a little bit, that might help."}, {"timestamp": [2347.28, 2355.76], "text": " Right. Is that any better? That's better. Okay, great stuff."}, {"timestamp": [2357.52, 2366.48], "text": " So this is a running cluster. We see the storage OS, storage software is running here,"}, {"timestamp": [2366.52, 2368.8], "text": " as well as the CSI software."}, {"timestamp": [2369.8, 2374.94], "text": " And it's a typical implementation of a Kubernetes cluster."}, {"timestamp": [2375.72, 2378.26], "text": " We'll focus on the application that's running."}, {"timestamp": [2378.26, 2382.56], "text": " So this is the MySQL pod."}, {"timestamp": [2383.2, 2386.16], "text": " So before we move forward,"}, {"timestamp": [2386.16, 2387.76], "text": " what I just want to show is,"}, {"timestamp": [2390.12, 2393.44], "text": " I want to show the pods"}, {"timestamp": [2394.36, 2398.1], "text": " and the YAML for that pods,"}, {"timestamp": [2399.16, 2402.14], "text": " which is running successfully here."}, {"timestamp": [2402.14, 2405.16], "text": " And I want to be able to also and I"}, {"timestamp": [2405.16, 2413.62], "text": " also want to show you the storage class. So we have the"}, {"timestamp": [2413.62, 2420.58], "text": " fast storage class here. And we can describe the storage class,"}, {"timestamp": [2421.46, 2424.38], "text": " which gives you the very simple information to say that this is"}, {"timestamp": [2424.38, 2429.0], "text": " using the CSI API to talk to API to talk to the storage system."}, {"timestamp": [2429.0, 2441.0], "text": " We can look at the PVC. So we have the PVC called data mySQL zero."}, {"timestamp": [2441.0, 2445.88], "text": " And it's connected to this volume."}, {"timestamp": [2445.88, 2448.0], "text": " So we can also see that volume."}, {"timestamp": [2448.0, 2450.4], "text": " We can see the persistent volume here."}, {"timestamp": [2450.4, 2456.68], "text": " So this is the persistent volume that claim is using."}, {"timestamp": [2458.42, 2469.54], "text": " What this means is that we now have MySQL running with a stateful set on our"}, {"timestamp": [2469.54, 2482.98], "text": " cluster on a persistent volume. So as an example I will show you the... we can"}, {"timestamp": [2482.98, 2487.94], "text": " connect to MySQL and quickly show the databases that are currently defined."}, {"timestamp": [2487.94, 2495.48], "text": " This is a blank install. So this is just the stuff that you get on a native, on a startup."}, {"timestamp": [2497.14, 2517.14], "text": " We will run a little bit of SQL to create a database called shop and create the table called books and create a fictional book called CNCF webinar into that database."}, {"timestamp": [2532.02, 2536.92], "text": " And we can now query the database and we can see that there is the table was created and the book CNCF webinar was inserted into the database."}, {"timestamp": [2536.92, 2546.44], "text": " So now what I'm just going to show you is this cluster is running on three nodes."}, {"timestamp": [2557.04, 2558.66], "text": " And the MySQL pod is running on the node name that ends in 3U J9R."}, {"timestamp": [2566.72, 2569.44], "text": " So what I'm going to do now is I'm going to use the Kubernetes cordon command"}, {"timestamp": [2577.2, 2578.4], "text": " to tell Kubernetes that I don't want any new workloads to be scheduled on that node."}, {"timestamp": [2587.36, 2588.16], "text": " And what I am going to do now is I'm going to kill the stateful set that's running on that node. So"}, {"timestamp": [2594.64, 2607.12], "text": " there we go. I've just deleted the pods for that stateful set. Kubernetes is going to see that the pods was killed and needs to reconcile desired states versus actual states. So it's now going in and creating a new instance"}, {"timestamp": [2607.12, 2611.18], "text": " on another node that ends in 3u j9b."}, {"timestamp": [2612.44, 2615.94], "text": " Hopefully that container will start up in a second."}, {"timestamp": [2630.82, 2632.82], "text": " Of course, this is where normally it takes two seconds, and today it's decided to take a little longer."}, {"timestamp": [2632.82, 2639.14], "text": " Alex, a few questions have piled up in the Q&A chat, so if you feel like you want"}, {"timestamp": [2639.14, 2642.24], "text": " to pick what to do at any point."}, {"timestamp": [2642.24, 2643.24], "text": " Okay."}, {"timestamp": [2643.24, 2646.04], "text": " Actually, that's a good thing."}, {"timestamp": [2646.2, 2648.4], "text": " I'll just finish off this demo now"}, {"timestamp": [2648.4, 2650.16], "text": " and we can do that."}, {"timestamp": [2650.5, 2651.82], "text": " So what we can see here is"}, {"timestamp": [2651.82, 2654.18], "text": " that the MySQL instance"}, {"timestamp": [2654.18, 2655.62], "text": " actually has now started"}, {"timestamp": [2655.62, 2657.12], "text": " on another node."}, {"timestamp": [2658.52, 2660.26], "text": " And what we should be able to do"}, {"timestamp": [2660.26, 2662.76], "text": " is we should be able to"}, {"timestamp": [2662.76, 2664.66], "text": " query the database again."}, {"timestamp": [2665.0, 2666.38], "text": " And what we see is we should be able to query the database again."}, {"timestamp": [2671.38, 2671.44], "text": " And what we see is we get the same information back."}, {"timestamp": [2674.96, 2678.24], "text": " So effectively what's happened here is the pod was terminated, Kubernetes restarted"}, {"timestamp": [2678.24, 2683.24], "text": " the stateful set on another node, reconnected the PVC"}, {"timestamp": [2683.4, 2687.22], "text": " and that persistent data was provided there."}, {"timestamp": [2687.22, 2699.38], "text": " So we have a system where using the orchestration capabilities of Kubernetes and the functionality"}, {"timestamp": [2699.38, 2706.1], "text": " of cognitive storage, it's now possible to run stateful services like databases within"}, {"timestamp": [2706.1, 2709.44], "text": " your Kubernetes cluster and incorporate them into your environment."}, {"timestamp": [2710.44, 2716.54], "text": " And it also means that you can now quite easily build anything as a service, right?"}, {"timestamp": [2716.64, 2721.2], "text": " So whether it's a database, a message queue, Prometheus services, Elasticsearch, Kafka,"}, {"timestamp": [2721.32, 2725.92], "text": " whatever that is, you can now run them as a service dynamically within"}, {"timestamp": [2726.8, 2730.72], "text": " your Kubernetes cluster with that persistent storage backend."}, {"timestamp": [2732.16, 2750.18], "text": " So I'll stop sharing that demo and go back to the slides very quickly. Where are we?"}, {"timestamp": [2752.76, 2753.52], "text": " Oh, my slide's closed."}, {"timestamp": [2753.96, 2754.36], "text": " Never mind."}, {"timestamp": [2754.96, 2755.58], "text": " I'll just talk."}, {"timestamp": [2757.54, 2757.76], "text": " I was only going to have a tanky slide up."}, {"timestamp": [2761.94, 2762.62], "text": " So we can go through and answer some of the questions."}, {"timestamp": [2766.48, 2766.9], "text": " So hopefully this provided some useful background."}, {"timestamp": [2768.68, 2768.86], "text": " I tried to make it, you know,"}, {"timestamp": [2771.76, 2771.94], "text": " I only tried to use StorageOS as an example,"}, {"timestamp": [2774.6, 2778.56], "text": " but, you know, hopefully this gave you a broader understanding of the storage landscape."}, {"timestamp": [2778.78, 2783.84], "text": " We'd love you to have a look at the landscape white paper,"}, {"timestamp": [2784.36, 2789.54], "text": " and it would be great to get feedback on that white paper"}, {"timestamp": [2789.54, 2793.08], "text": " because we're about to release the second version that's"}, {"timestamp": [2793.08, 2797.12], "text": " further expanded and updated."}, {"timestamp": [2797.12, 2804.72], "text": " There's a question about the meetups for the CNCF SIG"}, {"timestamp": [2804.72, 2806.08], "text": " and for StorageOS. For the CNCF SIG and for StorageOS."}, {"timestamp": [2806.08, 2809.9], "text": " For the CNCF SIG, we meet twice a month."}, {"timestamp": [2809.9, 2815.24], "text": " The meetings are in the CNCF public calendar."}, {"timestamp": [2815.24, 2818.12], "text": " It's the second Tuesday and the fourth, sorry,"}, {"timestamp": [2818.12, 2823.28], "text": " the second Wednesday and the fourth Wednesday of every month."}, {"timestamp": [2823.28, 2826.38], "text": " We had another question to say,"}, {"timestamp": [2826.38, 2830.48], "text": " can I limit containers to access to spec files"}, {"timestamp": [2830.48, 2834.4], "text": " or inherit the volume settings?"}, {"timestamp": [2835.66, 2838.78], "text": " So I'm gonna try and interpret that question."}, {"timestamp": [2838.78, 2843.78], "text": " So effectively the containers will be using,"}, {"timestamp": [2851.36, 2852.32], "text": " will be using the volumes and the volumes, just like the containers and the pods"}, {"timestamp": [2860.56, 2861.84], "text": " are created within the same concept of the Kubernetes access controls. So things like"}, {"timestamp": [2870.64, 2871.9], "text": " namespaces and access to those namespaces and the filters, et cetera, that apply to those namespaces also apply to the volume abstractions too."}, {"timestamp": [2876.16, 2886.16], "text": " There is a question about Ceph and the Rook operator. So that's a very good example of the concept of having frameworks and tools that are helping or that integrate with the storage system"}, {"timestamp": [2886.16, 2888.64], "text": " to provide the Kubernetes integration."}, {"timestamp": [2888.64, 2893.08], "text": " So, Rook is an operator and it's a framework"}, {"timestamp": [2893.08, 2896.44], "text": " for actually more than one storage system."}, {"timestamp": [2896.44, 2900.24], "text": " It's going through CNCF as a graduation process right now"}, {"timestamp": [2900.24, 2901.24], "text": " in the storage SIG."}, {"timestamp": [2902.32, 2907.08], "text": " And Rook can deploy a Ceph based storage system."}, {"timestamp": [2907.08, 2912.96], "text": " Ceph being a storage system which is fundamentally based on an underlying"}, {"timestamp": [2912.96, 2918.04], "text": " object store, but can provide block and file system semantics too."}, {"timestamp": [2921.12, 2926.0], "text": " Can multiple containers in a single pod share the same PVC?"}, {"timestamp": [2926.62, 2929.62], "text": " So the answer is yes."}, {"timestamp": [2930.36, 2932.24], "text": " There are two ways that this can happen."}, {"timestamp": [2932.74, 2942.34], "text": " If multiple containers within a pod can access the same read-write-once volume,"}, {"timestamp": [2942.52, 2946.56], "text": " if they are on the same node nodes typically. So this is something"}, {"timestamp": [2946.56, 2955.76], "text": " that some storage systems support. However, if you want to follow the storage patterns properly,"}, {"timestamp": [2955.76, 2965.12], "text": " it's best to use the read write many or a shared file system if many containers need to be able to access the same volume."}, {"timestamp": [2972.56, 2979.84], "text": " We had a question to ask if we can provide a little explanation for on-prem storage solutions"}, {"timestamp": [2979.84, 2990.48], "text": " for Kubernetes. So on-prem solutions are quite varied because of course, as we discussed, we have"}, {"timestamp": [2991.04, 2997.28], "text": " some of the traditional storage vendors, so maybe things like traditional physical"}, {"timestamp": [2997.28, 3003.92], "text": " hardware storage array type solutions, some of which have very well integrated"}, {"timestamp": [3009.16, 3010.14], "text": " some of which have very well integrated CSI drivers that can integrate with Kubernetes."}, {"timestamp": [3016.9, 3017.44], "text": " But likewise, there are a whole, you know, there are a suite of software-defined storage systems,"}, {"timestamp": [3024.3, 3030.34], "text": " you know, like StorageOS or Ceph and Rook, for example, that can be deployed on premise too. And, you know, there isn't an answer where I can say,"}, {"timestamp": [3030.46, 3037.16], "text": " you know, this is definitely the storage solution that you should use for on-prem. The reason being,"}, {"timestamp": [3037.26, 3041.96], "text": " you know, as we discussed, is that there is a whole suite of, you know, different attributes"}, {"timestamp": [3041.96, 3048.08], "text": " that you need to look at. And perhaps some decisions that might factor into the process"}, {"timestamp": [3048.08, 3053.34], "text": " might be cost-based or they might be platform compatibility-based."}, {"timestamp": [3053.94, 3058.18], "text": " So, for example, you might find it easier to deploy a software solution"}, {"timestamp": [3058.18, 3062.9], "text": " if you're running environments on-prem and in the cloud"}, {"timestamp": [3062.9, 3063.92], "text": " or some sort of hybrid."}, {"timestamp": [3066.0, 3072.34], "text": " But it's something that you need to understand from your backend system too."}, {"timestamp": [3074.06, 3077.12], "text": " There's a question to ask, is StorageOS a shared file system?"}, {"timestamp": [3078.0, 3080.16], "text": " How does it handle read-writes for multiple nodes?"}, {"timestamp": [3080.16, 3081.78], "text": " And do you handle file logs?"}, {"timestamp": [3081.8, 3082.62], "text": " and you handle file logs."}, {"timestamp": [3085.02, 3088.26], "text": " So what you'll find is that StorageOS can provide both"}, {"timestamp": [3088.26, 3091.08], "text": " read-write-once and read-write-many solutions"}, {"timestamp": [3091.08, 3094.76], "text": " and similar to some of the read-write-many solutions"}, {"timestamp": [3094.76, 3097.8], "text": " they are provided using a shared file system."}, {"timestamp": [3098.9, 3101.94], "text": " So in the case of something like Ceph, for example"}, {"timestamp": [3101.94, 3104.74], "text": " it might use the CephFS file system."}, {"timestamp": [3105.7, 3110.52], "text": " Other storage systems might be using something like NFS,"}, {"timestamp": [3110.52, 3114.6], "text": " for example, as the way of providing the shared file system"}, {"timestamp": [3114.6, 3116.66], "text": " across multiple nodes."}, {"timestamp": [3118.64, 3123.64], "text": " So in terms of how they handle things like file locks"}, {"timestamp": [3124.28, 3128.8], "text": " will be very dependent on the NFS implementation"}, {"timestamp": [3128.8, 3130.66], "text": " of the underlying storage system."}, {"timestamp": [3130.66, 3135.66], "text": " If they're using a modern NFS implementation"}, {"timestamp": [3135.88, 3138.76], "text": " and support things like NFS version four,"}, {"timestamp": [3138.76, 3140.72], "text": " then you should be able to handle state"}, {"timestamp": [3140.72, 3142.18], "text": " and lock failovers too."}, {"timestamp": [3144.5, 3148.04], "text": " Is there work being done to provide a more user-friendly platform with a"}, {"timestamp": [3148.5, 3150.26], "text": " shared file system approach?"}, {"timestamp": [3152.0, 3155.84], "text": " I find it difficult to provide a solution that will work on many platforms and"}, {"timestamp": [3155.84, 3159.82], "text": " clouds. Right. So, so that's, that's a good question."}, {"timestamp": [3159.86, 3164.48], "text": " I think if you're looking to find a solution that will work on many platforms"}, {"timestamp": [3164.48, 3165.28], "text": " and different"}, {"timestamp": [3165.28, 3171.48], "text": " clouds, you should be looking at some of the software-defined storage solutions that are"}, {"timestamp": [3171.48, 3171.88], "text": " out there."}, {"timestamp": [3171.88, 3178.34], "text": " There are a number of CNCF projects that provide software solutions, and there are a number"}, {"timestamp": [3178.34, 3183.74], "text": " of commercial vendors like StorageOS that provide those solutions too."}, {"timestamp": [3181.56, 3183.96], "text": " commercial vendors, you know, like storage, that provide those solutions too."}, {"timestamp": [3184.86, 3187.82], "text": " Software defined solutions typically are,"}, {"timestamp": [3188.94, 3190.96], "text": " typically are platform agnostics."}, {"timestamp": [3190.96, 3195.46], "text": " Although, you know, you may find that different solutions"}, {"timestamp": [3195.46, 3198.7], "text": " might be optimized or might have some caveats"}, {"timestamp": [3198.7, 3201.9], "text": " on different services or different cloud providers"}, {"timestamp": [3201.9, 3203.9], "text": " that they're optimized for that they run."}, {"timestamp": [3206.48, 3211.36], "text": " Can I depend on servers internal SSD was another question. So that's a very, very good question."}, {"timestamp": [3212.16, 3217.52], "text": " And this ties into again the software based solutions. So typically software based solutions"}, {"timestamp": [3217.52, 3226.88], "text": " like storage OS or Rook, for example, can use storage that's available on each node to provide a storage pool that"}, {"timestamp": [3226.88, 3233.2], "text": " effectively spans the different nodes within a cluster. So yes, you can use the Intuendal SSD,"}, {"timestamp": [3233.2, 3239.68], "text": " and effectively the software-defined storage system provides kind of like a storage persona"}, {"timestamp": [3239.68, 3247.44], "text": " to those nodes and allows you to turn those commodity disks or commodity systems into"}, {"timestamp": [3249.2, 3255.36], "text": " a storage service with different data services based on the software solution you're using."}, {"timestamp": [3257.44, 3264.96], "text": " Is there a CSI driver to allow accessing an object store via PVC? So the answer is yes and no."}, {"timestamp": [3271.52, 3280.18], "text": " object store via PVC? So the answer is yes and no. So specifically at PVC, no. The CSI API is focused on providing functionality to access volumes within a system, and those"}, {"timestamp": [3280.18, 3286.64], "text": " volumes typically mean block file or shared file. There are, however, a number of"}, {"timestamp": [3286.64, 3293.32], "text": " discussions which are happening in the Kubernetes storage SIG right now that are talking about"}, {"timestamp": [3293.32, 3301.68], "text": " providing an abstraction to define access to object stores and buckets and things like that"}, {"timestamp": [3301.68, 3305.04], "text": " through a Kubernetes abstraction layer."}, {"timestamp": [3306.04, 3312.24], "text": " So, you know, as I mentioned earlier, volumes are probably the most mature"}, {"timestamp": [3312.24, 3316.36], "text": " abstraction within Kubernetes when it comes to storage, things like object"}, {"timestamp": [3316.36, 3318.24], "text": " stores are happening right now."}, {"timestamp": [3318.24, 3319.92], "text": " So you should follow, watch this space."}, {"timestamp": [3320.36, 3324.36], "text": " And if you're interested in finding out details, join the Kubernetes"}, {"timestamp": [3324.4, 3326.6], "text": " storage SIG mailing lists."}, {"timestamp": [3326.6, 3337.16], "text": " And with that, we are one minute from time and I believe I've covered all of the questions"}, {"timestamp": [3337.16, 3338.86], "text": " in my list here."}, {"timestamp": [3338.86, 3352.44], "text": " Sanjeev, were there any other questions that maybe I missed out on?"}, {"timestamp": [3352.78, 3354.18], "text": " All right."}, {"timestamp": [3357.5, 3363.24], "text": " Well, in that case, I think, I think we're done. So I'd like to say thank you to everybody that joins the webinar."}, {"timestamp": [3363.08, 3364.62], "text": " to everybody that joins the webinar."}, {"timestamp": [3368.78, 3371.62], "text": " And we'll be sharing the information and the slides later on."}, {"timestamp": [3373.84, 3375.58], "text": " Yep. Thank you, Alex."}, {"timestamp": [3376.04, 3377.52], "text": " Thanks for a great presentation."}, {"timestamp": [3377.76, 3378.76], "text": " This was very useful."}, {"timestamp": [3379.06, 3379.72], "text": " I learned a lot."}, {"timestamp": [3381.28, 3383.06], "text": " Thank you to everyone for joining us."}, {"timestamp": [3383.26, 3387.76], "text": " The webinar recording and the slides will be online data today."}, {"timestamp": [3387.76, 3392.2], "text": " We look forward to seeing you all at a future CNCF webinar."}, {"timestamp": [3392.2, 3393.86], "text": " Stay safe and have a great day."}, {"timestamp": [3393.86, 3394.86], "text": " Thank you."}, {"timestamp": [3394.86, 3396.12], "text": " Thank you."}], "text": " Sanjeev Rampal, C-NCF Ambassador, Cisco, and C-NCF Ambassador, are here to talk about storage for Kubernetes. Sanjeev Rampal, C-NCF Ambassador, Cisco, and C-NCF Ambassador, are here to talk about storage for Kubernetes. Sanjeev Rampal, C-NCF Ambassador, and C-NCF Ambassador, are here to talk about storage for Kubernetes. Welcome to today's C-NCF webinar. Everything you need to know about storage for Kubernetes. Everything you need to know about storage for Kubernetes. My name is Sanjeev Rampal. I'm a principal engineer at Cisco and a CNCF ambassador. I'll be moderating today's webinar. We would like to welcome our presenter today, Alex Chirkop, founder and CEO at StorageOS. Before we get started, a few housekeeping items. During the webinar, you will not be able to talk as an attendee. There is a Q&A box at the bottom of your screen. Please feel free to drop your questions in there. And we'll get to as many as we can through the call and at the end. Note the Q&A box is different from the chat box. Please use the Q&A box. This is an official webinar of the CNCF and as such is subject to the CNCF Code of Conduct. Please do not add anything to the chat or questions that would be in violation of that Code of Conduct. Basically, please be respectful of your fellow participants and presenters. With that, I'm going to hand it over to Alex to kick off today's presentation. Please go ahead, Alex. So good morning, good afternoon, or good evening, wherever you are. Hope you're all staying safe and are all well. So just a little bit of introduction about myself. I'm one of the founders and the CEO of StorageOS, where we've been focusing on building a software-defined cloud-native storage platform. And we'll talk a little bit about what a cloud-native storage platform means. I'm also the co-chair of the CNCF storage SIG and in the storage SIG we've been working on providing facilities like educational content, like landscape documents, as well as working with the TOC on some of the items, on some of the project reviews for projects that are looking to join the CNCF or to graduate through the CNCF process. Before embarking on this startup adventure, I've spent 25 years in infrastructure engineering, you know, trying to build some of the larger infrastructure environments. to build some of the larger infrastructure environments. I'm gonna get a little plugin for the CNCF SIG storage. All the calls are fully open and we meet twice a month. Sometimes it's to cover project reviews and project presentations from the community and sometimes it's to work together on different contents that we share through the SIG repo. It would be really great to see some more members attend so feel free to sign up and we'd love to talk to you about the projects that we're working on in the CNCF. What I'm going to do in terms of agenda today is I'm going to talk a little bit about some of the challenges of storage in cloud-native environments and discuss some of the principles of what to look for in cloud-native storage environments. I'm then going to cover some of the aspects of the storage landscape, which are covered from the CNCF landscape white paper document that we've created. And I'm also going to talk about some of the internals of how Kubernetes uses APIs like CSI to work with different storage providers to manage storage within their environment. Godz was heard, we'll move ahead and have a little demo where I can show the use of some of the Kubernetes technologies like storage classes and PVCs and PVs to run a stateful workload like a database in Kubernetes. So first off, we want to discuss why is storage important. So I'm going to say something fairly controversial here. Despite everything about containers being stateless, there is no such thing as a stateless architecture, right? All applications are looking to store state somewhere, whether it is consuming, whether those applications are consuming services that exist outside of the Kubernetes cluster, or whether they're using services or storage functionality that lives within the Kubernetes cluster. Now, cloud native storage is a very different beast. When we talk about Kubernetes, we're very familiar with the concept of pets versus cattle, right? So the concept that nodes are specially curated and have special resources or special services is a complete anti-pattern to the way Kubernetes clusters are deployed. What we really want is we want an environment where your Kubernetes cluster is treated like cattle. So every node is homogeneous and can be used to deploy applications. and can be used to deploy applications. Now, in much the same way that today, a developer can use a bit of YAML to specify, hey, this is my application, this is what it looks like, it needs this amount of CPU, this amount of memory, and maybe some network connectivity. Kubernetes then goes away and takes that declaration or that piece of YAML and kind of does a really good job at playing Tetris with your infrastructure. So it abstracts away all of the services that are available in the infrastructure and does the best to fit the applications in the most efficient way to that deployment and makes sure that we maintain rules to maintain scalability or health. So based on the fact that applications within Kubernetes use this sort of functionality, Kubernetes use this sort of functionality. You should also look for a cloud native storage solution where the solution is both declarative and composable, right? And in order to do this, you're looking for a storage system that has a rich API-driven process that Kubernetes can interact with. So in much the same way that you specify CPU, memory, and network requirements, you should also be able to specify something like, you know, I need 100 gigabytes and it needs to have these sorts of storage attributes like replication or encryption applied. The second challenge we see with cloudative storage is that data needs to be able to follow applications, right? So in a traditional storage architecture, you're very often presenting volumes or consuming storage on specific servers or nodes or VMs. storage on specific servers or nodes or VMs. And in cloud-native storage, we have a major difference here. The storage isn't being consumed by the node, but rather it's being consumed by the application that's running on the node. And a lot of effort obviously has gone into containerizing the application and making the application portable. So this application can now run on any nodes in the cluster. So you need to make sure that the storage subsystem can also apply the same rules and effectively be able to follow the application wherever it moves within the data center or within the cluster. The other thing is, obviously, since Kubernetes does such a great job at abstracting away the infrastructure, allowing you to effectively deploy an application in much the same way, whether you're running bare metal on-prem or in VMs or in cloud instances, you're also looking for a storage system that can be platform agnostic and work across all of those different platforms too. And finally, and I know this is a little cliched, but I'll go as far as saying, you know, you want to look at the agility of the storage system too. So it's one of the things that needs to be considered because Kubernetes environments tends to be more dynamic. They are designed to be dynamically scaled and dynamically upgraded, and therefore nodes come and go and nodes are scaled up and scaled down. So you want a storage system that can adapt to the changing nature of the Kubernetes environment. And then finally, this is kind of obvious, right? The people are deploying the automation and using Kubernetes to automate everything with their infrastructure, right? And make it predictable and recreateable. So this kind of feeds on the concept of cattle versus pets too. That said, because we're looking to automate everything within the infrastructure, we also want to make sure that the automation applies to the storage environment and that the storage environment is consistently available and sort of protects the data within your Kubernetes cluster and can also provide the appropriate levels of performance and security that interact with the Kubernetes environment. So predictable, deterministic performance and security that natively works with Kubernetes access controls and Kubernetes namespaces, for example, are strong attributes that you should be looking out for. So I'm going to move into talking next about the CNCF storage landscape white paper. The storage landscape white paper is a document that we started working on now probably about 18, 24 months back. And we've had contributions and lots of reviews on the document. And what we've tried to do here is we've tried to explain the different components and different attributes of a storage system, covering where a storage system can be deployed, the various attributes of the storage system, the layers and the topology within a storage system, as well as how you access storage and the management interfaces that are used on the control plane for those storage systems. So the reason why this is important is because storage is a very broad topic, right? So we tend to think of storage traditionally as volumes, but in a cloud-native world, storage is any way you can persist data. So in the cloud-native world, you kind of have two types of methods of doing that. One is with traditional volumes and one is sort of API based methods, which includes things like object stores and databases and key value stores, for example. And more than ever before, it's becoming really important for developers to understand the storage attributes of their system and to understand how the storage system works. Because they need to ensure that those attributes match to what their application requires. So we'll talk a little bit about the attributes in a second. So we'll talk a little bit about the attributes in a second. The first point is there are lots of different ways of deploying storage within an environment, right? The more traditional hardware solutions are typically deployed in a data center. But obviously, some of those solutions have limitations on the portability and the use of those solutions within cloud environments. Software solutions tend to be more platform agnostic, and some software solutions and some of the projects that we're looking at in both commercial vendors and CNCF projects, you have software solutions that can be deployed as a container and the deployment can actually be automated through an orchestrator too. And finally of course there are storage services which can be consumed from the public cloud providers. So public cloud providers provide services like object stores or disk volumes too. So we talked a little bit about the storage attributes, but why is it important to understand what these different storage attributes mean? So when we drew up the landscape white paper, we classified the attributes into five different main types. Availability, scalability, performance, consistency, and durability. What we found was, as we were discussing these different attributes, is that each of these attributes are important to different aspects of an application. So for example, most applications have architecture patterns that depend on a storage subsystem to provide a layer of availability. So if an application needs to move between nodes or failover, it needs to be able to continue to access the same data, for example. be able to continue to access the same data, for example. Similarly, another lever or another aspect that is very important for some applications is scalability. Now, scalability, again, can be measured in a number of different ways. It could be the scalability of the number of operations or the throughput of that environment, or it could be things like the scalability of the number of concurrent clients, for example, that can connect into the system, or indeed the number of components. So does the system scale horizontally or does it scale vertically, for example? Similarly, we talked about deterministic performance, and often performance is one of the key measures of a storage system that people want to understand. But again, most storage system topologies have a number of compromises, and they are typically optimized for some combination of different performance parameters. So what we see is we see some storage systems, for example, that are highly optimized for low latency and are suitable, for example, for transactional systems, which require that low latency per operation, whereas other storage systems are optimized for throughput, for example, for things like data analytics or data warehousing type operations. When we talk about compromises and optimizations of the different storage systems, the other aspect to keep in mind is the consistency. So most systems will have some level of, you know, different levers on the consistency attributes that dramatically affect availability, scalability, and performance. And consistency is measured in two vectors. One is the amount of time that it takes to commit the data to non-volatile storage once it's been committed. And the second is the delay once that data has been committed to be able to access that consistently across all the different nodes in a cluster, right? And you'll find that some applications can tolerate eventual consistency and some applications need very strong synchronous consistency. And then finally, we look at durability, right? And durability sometimes gets confused with availability, but they are fundamentally different things. So availability is talking about the ability of storage to fail over and to move between nodes and to provide some level of redundancy. The durability is a measure of the way that the data is protected on the back end in the system, and that includes redundancy. But it also includes additional measures like, for example, the way the storage system protects against corruption on the underlying disk media, for example. So we move on then to the storage layers within a storage system. So in a storage system, it's now more common than ever that a typical environment will be composed of a number of different layers. And some of the layers can be intermingled from different systems. can be intermingled from different systems. So it's not uncommon to find different storage systems, for example, layers on top of each other to provide different services or different functionality. At the very top, you have the work that the orchestrator is doing, things like virtualizing the mount points and making sure that mount points are available on different nodes within a cluster and the integration into things like namespaces and the container bind lines for example. Another factor to consider within to consider within the storage layers is the topology that the storage systems use. There are storage systems that have a very centralized topology, perhaps because they have some proprietary hardware interconnects or they're designed for scaling vertically. And those sort of systems tend to be optimized for performance and low latency, but obviously they have the complexity of only being able to scale vertically. You then move into distributed systems, which tends to provide much better scaling capabilities by scaling horizontally rather than vertically. But distributed systems then have additional complexity and additional latency requirements that need to be taken into consideration because the data is spread out across more nodes and therefore across more network connectivity is important. And then there are also technologies which often apply to databases called sharding, for example, where scaling and distribution of data is done by filtering the data into different buckets and placing different buckets on different systems. And the last topology I'd like to talk about is hyperconverged, which is something that's becoming a bit more common nowadays. And what we're talking about here is an environment where nodes are simultaneously providing storage to a storage subsystem and used to provide storage capacity whilst also running applications and compute capabilities. The next layer down talks about the way the data is protected within those systems. at the way the data is protected within those systems. We have things like traditional systems that might use some form of RAID, which effectively creates parity or mirrors for the data. More commonly in distributed systems, we see erasure coding, which again is a way of creating, of splitting the data into multiple components and creating multiple fragments of parity and data that can be used to recover the data if any individual nodes goes down. And then we have the concept of replicas, which where data is replicated in its entirety to a number of different nodes. And often this is a big sort of play between performance, data protection, and availability and durability. So things like erasure coding provides amazing durability, but typically at a latency cost. but typically at a latency cost. And things like replicas provide a lower latency solution, but typically at the cost of using additional capacity. Now, one thing that mustn't be forgotten is the concept that every storage system also provides some layer of data services. So things like replication of data or snapshots or clones, which are point-in-time copies of data services. So things like replication of data or snapshots or clones, which are point in time copies of data, which are typically important for different workflows, whether it's, you know, providing disaster recovery or business continuity, or providing backup functionality in your system. And we can't forget the physical or the non-volatile layer, right? So, you know, from traditional spinning media to fast solid-state devices and moving forward to non-volatile, you know, memory class type components, each of those components offer a variety of different storage attributes when it comes to, you know, obviously performance, but also more importantly things like durability too. One of the things that's quite interesting is we try to put a table in place to compare the different storage topologies between local, remote, and distributed systems. And we kind of see that the topology comparison affects each of those storage attributes by quite an amount, right? So local systems, for example, are limited in availability, whereas remote and distributed systems have better availability and better scalability. But of course, performance tends to be lower in local systems. And we'll talk a little bit about state of locality in a minute. But obviously remote and distributed systems tend to have slightly higher latencies. So we move on then to the data access interfaces. And we talked a little bit earlier on about the concept of volumes and APIs, right? So it's really important to distinguish between the data access interface, which is what a container or an application uses to actually access the data, and the control plane that the orchestrator uses to do things like dynamic provisioning of volumes or management of the storage system. So it's probably fair to say that the most mature APIs that are available today with Kubernetes integration are volumes. So things like block devices, file systems and shared file systems. And a lot of databases or message queues or instrumentation like Prometheus, for example, will depend on being able to use these sorts of volumes. But likewise, of course, there are a whole suite of storage systems that provide object store interfaces or key value stores or databases that are accessed over an API. And those sorts of systems, for example, will typically be using that API over a network. Each of the different data access interfaces are typically suited to different sets of attributes. So what I'm going to do, what I'm going to let that settle in for a second and you can see some of the comparisons on the screen. So for example, you know, you typically expect block systems to perhaps have a lower latency or file systems to be able to provide the ability to share workloads across multiple nodes, for example. And object stores are well known for being able to scale to very large capacities, for example. But that said, one word of caution that caveats all of this is that, you know, we go back to the storage topologies and the layering. We often have to try and understand what is happening within a storage system, right? So sometimes if you have block devices, which are typically, you know, linked to, for example, a physical low latency device in the server. Block systems can now, block devices can now work remotely and can work on distributed storage systems and therefore they inherit the storage attributes of that distributed system. Similarly, for example, there are many file systems that are built on an object store backend and therefore they have the, you know, they inherit the latency and the availability and durability of the object store rather than just the attributes of the file system. So understanding the layering is fairly important when we're trying to look at these comparisons. And then we move on to the orchestration and management interfaces. So this is how things like dynamic provisioning work between Kubernetes and the storage system. So the container orchestrator of Kubernetes has a control plane interface. There are a number of these interfaces and they talk to the control plane in the storage system. Now, in some cases, the storage system supports the control plane APIs natively. And in some cases, the orchestrator is talking via a framework or a set of tools to provide the bridge between the orchestrator API and the storage system API. Of course, as we discussed before, the workloads talk to the data plane via the data access interface, which is very separate from the control plane interfaces. So you might ask, OK, we've listed a number of different control plane interfaces, but what do they all mean? So the key interface here is the container storage interface. The container storage interface is similar to CNI for networking or CRI for the runtime. It is a standard API which was adopted between orchestrators like Kubernetes and different storage vendors. So currently there are, I actually lost track, but there's easily 50 or more storage systems that support the CSI interface that integrate with Kubernetes. I'm highlighting CSI because this is the factor standard for interfacing Kubernetes to different storage systems and different storage services. In the past, we had drivers that were mainlined into the Kubernetes source, and we had the concept of Kubernetes flex volumes. But if you're trying to implement a new system nowadays, it's probably worth focusing entirely on CSI because that's the standard where all the development and advancements are happening today. So we'll talk a little bit now about how storage is configured in Kubernetes. So now that we talked about and we kind of set the scene of the storage system with all these different layers and different data access methods and different control plane access methods, what does this actually translate to in real life and how do these systems interact with Kubernetes? So we'll talk a little bit first about the concept of dynamic provisioning. So you remember when we said storage needs to be application-centric, and therefore that enables self-service and declarative and composable storage. How is this actually achieved? So the main abstraction layer here is called a storage class. So effectively, a storage class is a definition that specifies a driver interface, typically through CSI, that driver interface will be used by the storage system to provide and manage the storage, right? And this is in relation to dynamically provisioning the storage, but also things like attaching storage to physical nodes or to nodes within the cluster and mounting that storage and managing the storage lifecycle. So that's all well and good, but what does a storage class really look like? So a storage class is actually typically something really, really simple like this. The storage class defines a name. So in this case, we're calling it fast because you can create different storage classes for different types of environments. It might specify some labels or flags that are specific to the storage system. And it defines the provisioner. In this case, we've simplified it and just called it storageOS. But if we were using CSI, the provisioner would be a CSI provisioner. What this translates to then is how do developers who want to use that composable storage, how do they actually register what they need? So the constant here is a persistent volume claim. So within the definition of your application or your pods, you can make a persistent volume claim from the pool of storage that's linked to that storage class. Again, what does a persistent volume claim look like? Well, fundamentally, it's really, really simple. You give it a name. In this case, we're calling it a database volume. You tell it which storage class to use. In this case, we're calling it a database volume. You tell it which storage class to use. In this case, we're specifying the fast. And you specify the size of the storage. I'll talk a little bit about the access modes in a little bit. But fundamentally, all it is is you say, I'm going to give a name to my persistent volume claim. I'm going to use a particular storage class and it's this amount of capacity. It is also possible to pass things like labels which might affect the provisioning capabilities of which might be specific to a particular storage system too. What happens then behind the scenes is that Kubernetes talks over the storage interface to the storage system. The storage system creates a persistent volume. So we said that the developer makes a claim and the storage system replies by saying, hey, here you are. This is your persistent volume. You then reference that claim in the pod. And when your application in the pod is started, that persistent volume is connected into the pod. So moving forward a little bit, the pods. So moving forward a little bit, what does that actually look like? So this is an example of a simple, you know, an empty pods that just runs a sleep command and uses a PVC1 claim. So what we see here is when the PVC is requested, the storage system will create the persistent volume like we just described, and then that persistent volume is attached to a node and is mounted, typically in farlib-kubelet, a long path name in farlib-kubelet. Once that happens and the container is then started, that part in the node is bind mounted into the specified mount point, which in this case is slash MNT within the container namespace. So the application starts and now has access to a file system or that volume under, in this case, the slash mnt mount point. If that application then moves to different nodes within the cluster, the reverse happens. The persistent volume is detached and reattached on another node and then remounted and can be reused by an application on the other node. So if you recall, we talked a little bit about volume access modes too. So in the volume access modes, we have two typical modes. One is RedriveOnce and one is Redrive many. So read write once means that the volume is mounted and accessed exclusively only by one node. This is this is typically the type of storage that you'd see from say block storage services. We also have the read write many and this will typically be used to access a shared file system. So so effectively this gives the ability to mount a file system on multiple nodes simultaneously. And that can be used for different storage patterns, perhaps, where a common file system needs to be available to provide a consistent level of config or a consistent level of reference data to multiple nodes within a system. Okay. So what I'm going to do is I'm going to show a very, very quick example, assuming everything works, of provisioning a stateful workload and moving a stateful workload from one node to another in a Kubernetes cluster. For reference, I'm just using one of the simple examples that's available on the StorageOS website. But obviously, you can run any application with any number of different storage systems. In this particular example, I'm going to start up a MySQL database and I'm using the free StorageOS developer edition, which is free forever and available on our website. The stateful set definition effectively tells Kubernetes to make a claim for a MySQL database and to start it up with Firelib MySQL in the mount part. So I've already done this. So what I'm going to do now is I will briefly unshare my screen and I will now share my demo. Sanjeev, can you just confirm that the demo screen is loaded? Yes, Alex. Looks good. Awesome. All right. So I'm going to be using a little tool called K9S to provide visibility of what's going on in the cluster. K9S is an open source tool, but it's really great at visualizing what's going on in the Kubernetes cluster. One quick one, Alex, if you could maybe magnify the font a little bit, that might help. Right. Is that any better? That's better. Okay, great stuff. So this is a running cluster. We see the storage OS, storage software is running here, as well as the CSI software. And it's a typical implementation of a Kubernetes cluster. We'll focus on the application that's running. So this is the MySQL pod. So before we move forward, what I just want to show is, I want to show the pods and the YAML for that pods, which is running successfully here. And I want to be able to also and I also want to show you the storage class. So we have the fast storage class here. And we can describe the storage class, which gives you the very simple information to say that this is using the CSI API to talk to API to talk to the storage system. We can look at the PVC. So we have the PVC called data mySQL zero. And it's connected to this volume. So we can also see that volume. We can see the persistent volume here. So this is the persistent volume that claim is using. What this means is that we now have MySQL running with a stateful set on our cluster on a persistent volume. So as an example I will show you the... we can connect to MySQL and quickly show the databases that are currently defined. This is a blank install. So this is just the stuff that you get on a native, on a startup. We will run a little bit of SQL to create a database called shop and create the table called books and create a fictional book called CNCF webinar into that database. And we can now query the database and we can see that there is the table was created and the book CNCF webinar was inserted into the database. So now what I'm just going to show you is this cluster is running on three nodes. And the MySQL pod is running on the node name that ends in 3U J9R. So what I'm going to do now is I'm going to use the Kubernetes cordon command to tell Kubernetes that I don't want any new workloads to be scheduled on that node. And what I am going to do now is I'm going to kill the stateful set that's running on that node. So there we go. I've just deleted the pods for that stateful set. Kubernetes is going to see that the pods was killed and needs to reconcile desired states versus actual states. So it's now going in and creating a new instance on another node that ends in 3u j9b. Hopefully that container will start up in a second. Of course, this is where normally it takes two seconds, and today it's decided to take a little longer. Alex, a few questions have piled up in the Q&A chat, so if you feel like you want to pick what to do at any point. Okay. Actually, that's a good thing. I'll just finish off this demo now and we can do that. So what we can see here is that the MySQL instance actually has now started on another node. And what we should be able to do is we should be able to query the database again. And what we see is we should be able to query the database again. And what we see is we get the same information back. So effectively what's happened here is the pod was terminated, Kubernetes restarted the stateful set on another node, reconnected the PVC and that persistent data was provided there. So we have a system where using the orchestration capabilities of Kubernetes and the functionality of cognitive storage, it's now possible to run stateful services like databases within your Kubernetes cluster and incorporate them into your environment. And it also means that you can now quite easily build anything as a service, right? So whether it's a database, a message queue, Prometheus services, Elasticsearch, Kafka, whatever that is, you can now run them as a service dynamically within your Kubernetes cluster with that persistent storage backend. So I'll stop sharing that demo and go back to the slides very quickly. Where are we? Oh, my slide's closed. Never mind. I'll just talk. I was only going to have a tanky slide up. So we can go through and answer some of the questions. So hopefully this provided some useful background. I tried to make it, you know, I only tried to use StorageOS as an example, but, you know, hopefully this gave you a broader understanding of the storage landscape. We'd love you to have a look at the landscape white paper, and it would be great to get feedback on that white paper because we're about to release the second version that's further expanded and updated. There's a question about the meetups for the CNCF SIG and for StorageOS. For the CNCF SIG and for StorageOS. For the CNCF SIG, we meet twice a month. The meetings are in the CNCF public calendar. It's the second Tuesday and the fourth, sorry, the second Wednesday and the fourth Wednesday of every month. We had another question to say, can I limit containers to access to spec files or inherit the volume settings? So I'm gonna try and interpret that question. So effectively the containers will be using, will be using the volumes and the volumes, just like the containers and the pods are created within the same concept of the Kubernetes access controls. So things like namespaces and access to those namespaces and the filters, et cetera, that apply to those namespaces also apply to the volume abstractions too. There is a question about Ceph and the Rook operator. So that's a very good example of the concept of having frameworks and tools that are helping or that integrate with the storage system to provide the Kubernetes integration. So, Rook is an operator and it's a framework for actually more than one storage system. It's going through CNCF as a graduation process right now in the storage SIG. And Rook can deploy a Ceph based storage system. Ceph being a storage system which is fundamentally based on an underlying object store, but can provide block and file system semantics too. Can multiple containers in a single pod share the same PVC? So the answer is yes. There are two ways that this can happen. If multiple containers within a pod can access the same read-write-once volume, if they are on the same node nodes typically. So this is something that some storage systems support. However, if you want to follow the storage patterns properly, it's best to use the read write many or a shared file system if many containers need to be able to access the same volume. We had a question to ask if we can provide a little explanation for on-prem storage solutions for Kubernetes. So on-prem solutions are quite varied because of course, as we discussed, we have some of the traditional storage vendors, so maybe things like traditional physical hardware storage array type solutions, some of which have very well integrated some of which have very well integrated CSI drivers that can integrate with Kubernetes. But likewise, there are a whole, you know, there are a suite of software-defined storage systems, you know, like StorageOS or Ceph and Rook, for example, that can be deployed on premise too. And, you know, there isn't an answer where I can say, you know, this is definitely the storage solution that you should use for on-prem. The reason being, you know, as we discussed, is that there is a whole suite of, you know, different attributes that you need to look at. And perhaps some decisions that might factor into the process might be cost-based or they might be platform compatibility-based. So, for example, you might find it easier to deploy a software solution if you're running environments on-prem and in the cloud or some sort of hybrid. But it's something that you need to understand from your backend system too. There's a question to ask, is StorageOS a shared file system? How does it handle read-writes for multiple nodes? And do you handle file logs? and you handle file logs. So what you'll find is that StorageOS can provide both read-write-once and read-write-many solutions and similar to some of the read-write-many solutions they are provided using a shared file system. So in the case of something like Ceph, for example it might use the CephFS file system. Other storage systems might be using something like NFS, for example, as the way of providing the shared file system across multiple nodes. So in terms of how they handle things like file locks will be very dependent on the NFS implementation of the underlying storage system. If they're using a modern NFS implementation and support things like NFS version four, then you should be able to handle state and lock failovers too. Is there work being done to provide a more user-friendly platform with a shared file system approach? I find it difficult to provide a solution that will work on many platforms and clouds. Right. So, so that's, that's a good question. I think if you're looking to find a solution that will work on many platforms and different clouds, you should be looking at some of the software-defined storage solutions that are out there. There are a number of CNCF projects that provide software solutions, and there are a number of commercial vendors like StorageOS that provide those solutions too. commercial vendors, you know, like storage, that provide those solutions too. Software defined solutions typically are, typically are platform agnostics. Although, you know, you may find that different solutions might be optimized or might have some caveats on different services or different cloud providers that they're optimized for that they run. Can I depend on servers internal SSD was another question. So that's a very, very good question. And this ties into again the software based solutions. So typically software based solutions like storage OS or Rook, for example, can use storage that's available on each node to provide a storage pool that effectively spans the different nodes within a cluster. So yes, you can use the Intuendal SSD, and effectively the software-defined storage system provides kind of like a storage persona to those nodes and allows you to turn those commodity disks or commodity systems into a storage service with different data services based on the software solution you're using. Is there a CSI driver to allow accessing an object store via PVC? So the answer is yes and no. object store via PVC? So the answer is yes and no. So specifically at PVC, no. The CSI API is focused on providing functionality to access volumes within a system, and those volumes typically mean block file or shared file. There are, however, a number of discussions which are happening in the Kubernetes storage SIG right now that are talking about providing an abstraction to define access to object stores and buckets and things like that through a Kubernetes abstraction layer. So, you know, as I mentioned earlier, volumes are probably the most mature abstraction within Kubernetes when it comes to storage, things like object stores are happening right now. So you should follow, watch this space. And if you're interested in finding out details, join the Kubernetes storage SIG mailing lists. And with that, we are one minute from time and I believe I've covered all of the questions in my list here. Sanjeev, were there any other questions that maybe I missed out on? All right. Well, in that case, I think, I think we're done. So I'd like to say thank you to everybody that joins the webinar. to everybody that joins the webinar. And we'll be sharing the information and the slides later on. Yep. Thank you, Alex. Thanks for a great presentation. This was very useful. I learned a lot. Thank you to everyone for joining us. The webinar recording and the slides will be online data today. We look forward to seeing you all at a future CNCF webinar. Stay safe and have a great day. Thank you. Thank you."}